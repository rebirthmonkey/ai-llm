{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install bitsandbytes"
      ],
      "metadata": {
        "id": "9jpTKSZEtznj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "status": "ok",
          "timestamp": 1762668870608,
          "user_tz": -480,
          "elapsed": 4612,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "e72ed869-af7a-4214-91b8-21567eff68e9"
      },
      "id": "9jpTKSZEtznj",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: bitsandbytes in /usr/local/lib/python3.12/dist-packages (0.48.2)\n",
            "Requirement already satisfied: torch<3,>=2.3 in /usr/local/lib/python3.12/dist-packages (from bitsandbytes) (2.8.0+cu126)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from bitsandbytes) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.12/dist-packages (from bitsandbytes) (25.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (3.4.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch<3,>=2.3->bitsandbytes) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch<3,>=2.3->bitsandbytes) (3.0.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "id": "KX2tzIeHPhX3p8p5SNeJcizV",
      "metadata": {
        "tags": [],
        "id": "KX2tzIeHPhX3p8p5SNeJcizV",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1762668882724,
          "user_tz": -480,
          "elapsed": 5419,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "source": [
        "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
        "import torch\n",
        "\n",
        "model_name = \"Qwen/Qwen3-0.6B\"\n",
        "# model_name = \"Qwen/Qwen3-4B-Instruct-2507\"\n",
        "# model_name = \"Qwen/Qwen3-1.7B\""
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
        "import torch\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_name,\n",
        "    trust_remote_code=True,\n",
        "    torch_dtype=torch.float16,  # 使用float16节省内存\n",
        "    device_map=\"auto\",\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 413
        },
        "id": "8bvjD0KJfiEL",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1762668952370,
          "user_tz": -480,
          "elapsed": 8100,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "2736c07a-49e0-4468-bc8b-54817409bd26"
      },
      "id": "8bvjD0KJfiEL",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`torch_dtype` is deprecated! Use `dtype` instead!\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for name, param in model.named_parameters():\n",
        "    print(f\"{name}: {param.device}\")"
      ],
      "metadata": {
        "id": "9e7tL3b4gvBO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "status": "ok",
          "timestamp": 1762668963618,
          "user_tz": -480,
          "elapsed": 298,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "b774ec3e-2d24-4066-a936-928b8e06e880"
      },
      "id": "9e7tL3b4gvBO",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model.embed_tokens.weight: cuda:7\n",
            "model.layers.0.self_attn.q_proj.weight: cuda:7\n",
            "model.layers.0.self_attn.k_proj.weight: cuda:7\n",
            "model.layers.0.self_attn.v_proj.weight: cuda:7\n",
            "model.layers.0.self_attn.o_proj.weight: cuda:7\n",
            "model.layers.0.self_attn.q_norm.weight: cuda:7\n",
            "model.layers.0.self_attn.k_norm.weight: cuda:7\n",
            "model.layers.0.mlp.gate_proj.weight: cuda:7\n",
            "model.layers.0.mlp.up_proj.weight: cuda:7\n",
            "model.layers.0.mlp.down_proj.weight: cuda:7\n",
            "model.layers.0.input_layernorm.weight: cuda:7\n",
            "model.layers.0.post_attention_layernorm.weight: cuda:7\n",
            "model.layers.1.self_attn.q_proj.weight: cuda:7\n",
            "model.layers.1.self_attn.k_proj.weight: cuda:7\n",
            "model.layers.1.self_attn.v_proj.weight: cuda:7\n",
            "model.layers.1.self_attn.o_proj.weight: cuda:7\n",
            "model.layers.1.self_attn.q_norm.weight: cuda:7\n",
            "model.layers.1.self_attn.k_norm.weight: cuda:7\n",
            "model.layers.1.mlp.gate_proj.weight: cuda:7\n",
            "model.layers.1.mlp.up_proj.weight: cuda:7\n",
            "model.layers.1.mlp.down_proj.weight: cuda:7\n",
            "model.layers.1.input_layernorm.weight: cuda:7\n",
            "model.layers.1.post_attention_layernorm.weight: cuda:7\n",
            "model.layers.2.self_attn.q_proj.weight: cuda:7\n",
            "model.layers.2.self_attn.k_proj.weight: cuda:7\n",
            "model.layers.2.self_attn.v_proj.weight: cuda:7\n",
            "model.layers.2.self_attn.o_proj.weight: cuda:7\n",
            "model.layers.2.self_attn.q_norm.weight: cuda:7\n",
            "model.layers.2.self_attn.k_norm.weight: cuda:7\n",
            "model.layers.2.mlp.gate_proj.weight: cuda:7\n",
            "model.layers.2.mlp.up_proj.weight: cuda:7\n",
            "model.layers.2.mlp.down_proj.weight: cuda:7\n",
            "model.layers.2.input_layernorm.weight: cuda:7\n",
            "model.layers.2.post_attention_layernorm.weight: cuda:7\n",
            "model.layers.3.self_attn.q_proj.weight: cuda:7\n",
            "model.layers.3.self_attn.k_proj.weight: cuda:7\n",
            "model.layers.3.self_attn.v_proj.weight: cuda:7\n",
            "model.layers.3.self_attn.o_proj.weight: cuda:7\n",
            "model.layers.3.self_attn.q_norm.weight: cuda:7\n",
            "model.layers.3.self_attn.k_norm.weight: cuda:7\n",
            "model.layers.3.mlp.gate_proj.weight: cuda:7\n",
            "model.layers.3.mlp.up_proj.weight: cuda:7\n",
            "model.layers.3.mlp.down_proj.weight: cuda:7\n",
            "model.layers.3.input_layernorm.weight: cuda:7\n",
            "model.layers.3.post_attention_layernorm.weight: cuda:7\n",
            "model.layers.4.self_attn.q_proj.weight: cuda:7\n",
            "model.layers.4.self_attn.k_proj.weight: cuda:7\n",
            "model.layers.4.self_attn.v_proj.weight: cuda:7\n",
            "model.layers.4.self_attn.o_proj.weight: cuda:7\n",
            "model.layers.4.self_attn.q_norm.weight: cuda:7\n",
            "model.layers.4.self_attn.k_norm.weight: cuda:7\n",
            "model.layers.4.mlp.gate_proj.weight: cuda:7\n",
            "model.layers.4.mlp.up_proj.weight: cuda:7\n",
            "model.layers.4.mlp.down_proj.weight: cuda:7\n",
            "model.layers.4.input_layernorm.weight: cuda:7\n",
            "model.layers.4.post_attention_layernorm.weight: cuda:7\n",
            "model.layers.5.self_attn.q_proj.weight: cuda:7\n",
            "model.layers.5.self_attn.k_proj.weight: cuda:7\n",
            "model.layers.5.self_attn.v_proj.weight: cuda:7\n",
            "model.layers.5.self_attn.o_proj.weight: cuda:7\n",
            "model.layers.5.self_attn.q_norm.weight: cuda:7\n",
            "model.layers.5.self_attn.k_norm.weight: cuda:7\n",
            "model.layers.5.mlp.gate_proj.weight: cuda:7\n",
            "model.layers.5.mlp.up_proj.weight: cuda:7\n",
            "model.layers.5.mlp.down_proj.weight: cuda:7\n",
            "model.layers.5.input_layernorm.weight: cuda:7\n",
            "model.layers.5.post_attention_layernorm.weight: cuda:7\n",
            "model.layers.6.self_attn.q_proj.weight: cuda:7\n",
            "model.layers.6.self_attn.k_proj.weight: cuda:7\n",
            "model.layers.6.self_attn.v_proj.weight: cuda:7\n",
            "model.layers.6.self_attn.o_proj.weight: cuda:7\n",
            "model.layers.6.self_attn.q_norm.weight: cuda:7\n",
            "model.layers.6.self_attn.k_norm.weight: cuda:7\n",
            "model.layers.6.mlp.gate_proj.weight: cuda:7\n",
            "model.layers.6.mlp.up_proj.weight: cuda:7\n",
            "model.layers.6.mlp.down_proj.weight: cuda:7\n",
            "model.layers.6.input_layernorm.weight: cuda:7\n",
            "model.layers.6.post_attention_layernorm.weight: cuda:7\n",
            "model.layers.7.self_attn.q_proj.weight: cuda:7\n",
            "model.layers.7.self_attn.k_proj.weight: cuda:7\n",
            "model.layers.7.self_attn.v_proj.weight: cuda:7\n",
            "model.layers.7.self_attn.o_proj.weight: cuda:7\n",
            "model.layers.7.self_attn.q_norm.weight: cuda:7\n",
            "model.layers.7.self_attn.k_norm.weight: cuda:7\n",
            "model.layers.7.mlp.gate_proj.weight: cuda:7\n",
            "model.layers.7.mlp.up_proj.weight: cuda:7\n",
            "model.layers.7.mlp.down_proj.weight: cuda:7\n",
            "model.layers.7.input_layernorm.weight: cuda:7\n",
            "model.layers.7.post_attention_layernorm.weight: cuda:7\n",
            "model.layers.8.self_attn.q_proj.weight: cuda:7\n",
            "model.layers.8.self_attn.k_proj.weight: cuda:7\n",
            "model.layers.8.self_attn.v_proj.weight: cuda:7\n",
            "model.layers.8.self_attn.o_proj.weight: cuda:7\n",
            "model.layers.8.self_attn.q_norm.weight: cuda:7\n",
            "model.layers.8.self_attn.k_norm.weight: cuda:7\n",
            "model.layers.8.mlp.gate_proj.weight: cuda:7\n",
            "model.layers.8.mlp.up_proj.weight: cuda:7\n",
            "model.layers.8.mlp.down_proj.weight: cuda:7\n",
            "model.layers.8.input_layernorm.weight: cuda:7\n",
            "model.layers.8.post_attention_layernorm.weight: cuda:7\n",
            "model.layers.9.self_attn.q_proj.weight: cuda:7\n",
            "model.layers.9.self_attn.k_proj.weight: cuda:7\n",
            "model.layers.9.self_attn.v_proj.weight: cuda:7\n",
            "model.layers.9.self_attn.o_proj.weight: cuda:7\n",
            "model.layers.9.self_attn.q_norm.weight: cuda:7\n",
            "model.layers.9.self_attn.k_norm.weight: cuda:7\n",
            "model.layers.9.mlp.gate_proj.weight: cuda:7\n",
            "model.layers.9.mlp.up_proj.weight: cuda:7\n",
            "model.layers.9.mlp.down_proj.weight: cuda:7\n",
            "model.layers.9.input_layernorm.weight: cuda:7\n",
            "model.layers.9.post_attention_layernorm.weight: cuda:7\n",
            "model.layers.10.self_attn.q_proj.weight: cuda:7\n",
            "model.layers.10.self_attn.k_proj.weight: cuda:7\n",
            "model.layers.10.self_attn.v_proj.weight: cuda:7\n",
            "model.layers.10.self_attn.o_proj.weight: cuda:7\n",
            "model.layers.10.self_attn.q_norm.weight: cuda:7\n",
            "model.layers.10.self_attn.k_norm.weight: cuda:7\n",
            "model.layers.10.mlp.gate_proj.weight: cuda:7\n",
            "model.layers.10.mlp.up_proj.weight: cuda:7\n",
            "model.layers.10.mlp.down_proj.weight: cuda:7\n",
            "model.layers.10.input_layernorm.weight: cuda:7\n",
            "model.layers.10.post_attention_layernorm.weight: cuda:7\n",
            "model.layers.11.self_attn.q_proj.weight: cuda:7\n",
            "model.layers.11.self_attn.k_proj.weight: cuda:7\n",
            "model.layers.11.self_attn.v_proj.weight: cuda:7\n",
            "model.layers.11.self_attn.o_proj.weight: cuda:7\n",
            "model.layers.11.self_attn.q_norm.weight: cuda:7\n",
            "model.layers.11.self_attn.k_norm.weight: cuda:7\n",
            "model.layers.11.mlp.gate_proj.weight: cuda:7\n",
            "model.layers.11.mlp.up_proj.weight: cuda:7\n",
            "model.layers.11.mlp.down_proj.weight: cuda:7\n",
            "model.layers.11.input_layernorm.weight: cuda:7\n",
            "model.layers.11.post_attention_layernorm.weight: cuda:7\n",
            "model.layers.12.self_attn.q_proj.weight: cuda:7\n",
            "model.layers.12.self_attn.k_proj.weight: cuda:7\n",
            "model.layers.12.self_attn.v_proj.weight: cuda:7\n",
            "model.layers.12.self_attn.o_proj.weight: cuda:7\n",
            "model.layers.12.self_attn.q_norm.weight: cuda:7\n",
            "model.layers.12.self_attn.k_norm.weight: cuda:7\n",
            "model.layers.12.mlp.gate_proj.weight: cuda:7\n",
            "model.layers.12.mlp.up_proj.weight: cuda:7\n",
            "model.layers.12.mlp.down_proj.weight: cuda:7\n",
            "model.layers.12.input_layernorm.weight: cuda:7\n",
            "model.layers.12.post_attention_layernorm.weight: cuda:7\n",
            "model.layers.13.self_attn.q_proj.weight: cuda:7\n",
            "model.layers.13.self_attn.k_proj.weight: cuda:7\n",
            "model.layers.13.self_attn.v_proj.weight: cuda:7\n",
            "model.layers.13.self_attn.o_proj.weight: cuda:7\n",
            "model.layers.13.self_attn.q_norm.weight: cuda:7\n",
            "model.layers.13.self_attn.k_norm.weight: cuda:7\n",
            "model.layers.13.mlp.gate_proj.weight: cuda:7\n",
            "model.layers.13.mlp.up_proj.weight: cuda:7\n",
            "model.layers.13.mlp.down_proj.weight: cuda:7\n",
            "model.layers.13.input_layernorm.weight: cuda:7\n",
            "model.layers.13.post_attention_layernorm.weight: cuda:7\n",
            "model.layers.14.self_attn.q_proj.weight: cuda:7\n",
            "model.layers.14.self_attn.k_proj.weight: cuda:7\n",
            "model.layers.14.self_attn.v_proj.weight: cuda:7\n",
            "model.layers.14.self_attn.o_proj.weight: cuda:7\n",
            "model.layers.14.self_attn.q_norm.weight: cuda:7\n",
            "model.layers.14.self_attn.k_norm.weight: cuda:7\n",
            "model.layers.14.mlp.gate_proj.weight: cuda:7\n",
            "model.layers.14.mlp.up_proj.weight: cuda:7\n",
            "model.layers.14.mlp.down_proj.weight: cuda:7\n",
            "model.layers.14.input_layernorm.weight: cuda:7\n",
            "model.layers.14.post_attention_layernorm.weight: cuda:7\n",
            "model.layers.15.self_attn.q_proj.weight: cuda:7\n",
            "model.layers.15.self_attn.k_proj.weight: cuda:7\n",
            "model.layers.15.self_attn.v_proj.weight: cuda:7\n",
            "model.layers.15.self_attn.o_proj.weight: cuda:7\n",
            "model.layers.15.self_attn.q_norm.weight: cuda:7\n",
            "model.layers.15.self_attn.k_norm.weight: cuda:7\n",
            "model.layers.15.mlp.gate_proj.weight: cuda:7\n",
            "model.layers.15.mlp.up_proj.weight: cuda:7\n",
            "model.layers.15.mlp.down_proj.weight: cuda:7\n",
            "model.layers.15.input_layernorm.weight: cuda:7\n",
            "model.layers.15.post_attention_layernorm.weight: cuda:7\n",
            "model.layers.16.self_attn.q_proj.weight: cuda:7\n",
            "model.layers.16.self_attn.k_proj.weight: cuda:7\n",
            "model.layers.16.self_attn.v_proj.weight: cuda:7\n",
            "model.layers.16.self_attn.o_proj.weight: cuda:7\n",
            "model.layers.16.self_attn.q_norm.weight: cuda:7\n",
            "model.layers.16.self_attn.k_norm.weight: cuda:7\n",
            "model.layers.16.mlp.gate_proj.weight: cuda:7\n",
            "model.layers.16.mlp.up_proj.weight: cuda:7\n",
            "model.layers.16.mlp.down_proj.weight: cuda:7\n",
            "model.layers.16.input_layernorm.weight: cuda:7\n",
            "model.layers.16.post_attention_layernorm.weight: cuda:7\n",
            "model.layers.17.self_attn.q_proj.weight: cuda:7\n",
            "model.layers.17.self_attn.k_proj.weight: cuda:7\n",
            "model.layers.17.self_attn.v_proj.weight: cuda:7\n",
            "model.layers.17.self_attn.o_proj.weight: cuda:7\n",
            "model.layers.17.self_attn.q_norm.weight: cuda:7\n",
            "model.layers.17.self_attn.k_norm.weight: cuda:7\n",
            "model.layers.17.mlp.gate_proj.weight: cuda:7\n",
            "model.layers.17.mlp.up_proj.weight: cuda:7\n",
            "model.layers.17.mlp.down_proj.weight: cuda:7\n",
            "model.layers.17.input_layernorm.weight: cuda:7\n",
            "model.layers.17.post_attention_layernorm.weight: cuda:7\n",
            "model.layers.18.self_attn.q_proj.weight: cuda:7\n",
            "model.layers.18.self_attn.k_proj.weight: cuda:7\n",
            "model.layers.18.self_attn.v_proj.weight: cuda:7\n",
            "model.layers.18.self_attn.o_proj.weight: cuda:7\n",
            "model.layers.18.self_attn.q_norm.weight: cuda:7\n",
            "model.layers.18.self_attn.k_norm.weight: cuda:7\n",
            "model.layers.18.mlp.gate_proj.weight: cuda:7\n",
            "model.layers.18.mlp.up_proj.weight: cuda:7\n",
            "model.layers.18.mlp.down_proj.weight: cuda:7\n",
            "model.layers.18.input_layernorm.weight: cuda:7\n",
            "model.layers.18.post_attention_layernorm.weight: cuda:7\n",
            "model.layers.19.self_attn.q_proj.weight: cuda:7\n",
            "model.layers.19.self_attn.k_proj.weight: cuda:7\n",
            "model.layers.19.self_attn.v_proj.weight: cuda:7\n",
            "model.layers.19.self_attn.o_proj.weight: cuda:7\n",
            "model.layers.19.self_attn.q_norm.weight: cuda:7\n",
            "model.layers.19.self_attn.k_norm.weight: cuda:7\n",
            "model.layers.19.mlp.gate_proj.weight: cuda:7\n",
            "model.layers.19.mlp.up_proj.weight: cuda:7\n",
            "model.layers.19.mlp.down_proj.weight: cuda:7\n",
            "model.layers.19.input_layernorm.weight: cuda:7\n",
            "model.layers.19.post_attention_layernorm.weight: cuda:7\n",
            "model.layers.20.self_attn.q_proj.weight: cuda:7\n",
            "model.layers.20.self_attn.k_proj.weight: cuda:7\n",
            "model.layers.20.self_attn.v_proj.weight: cuda:7\n",
            "model.layers.20.self_attn.o_proj.weight: cuda:7\n",
            "model.layers.20.self_attn.q_norm.weight: cuda:7\n",
            "model.layers.20.self_attn.k_norm.weight: cuda:7\n",
            "model.layers.20.mlp.gate_proj.weight: cuda:7\n",
            "model.layers.20.mlp.up_proj.weight: cuda:7\n",
            "model.layers.20.mlp.down_proj.weight: cuda:7\n",
            "model.layers.20.input_layernorm.weight: cuda:7\n",
            "model.layers.20.post_attention_layernorm.weight: cuda:7\n",
            "model.layers.21.self_attn.q_proj.weight: cuda:7\n",
            "model.layers.21.self_attn.k_proj.weight: cuda:7\n",
            "model.layers.21.self_attn.v_proj.weight: cuda:7\n",
            "model.layers.21.self_attn.o_proj.weight: cuda:7\n",
            "model.layers.21.self_attn.q_norm.weight: cuda:7\n",
            "model.layers.21.self_attn.k_norm.weight: cuda:7\n",
            "model.layers.21.mlp.gate_proj.weight: cuda:7\n",
            "model.layers.21.mlp.up_proj.weight: cuda:7\n",
            "model.layers.21.mlp.down_proj.weight: cuda:7\n",
            "model.layers.21.input_layernorm.weight: cuda:7\n",
            "model.layers.21.post_attention_layernorm.weight: cuda:7\n",
            "model.layers.22.self_attn.q_proj.weight: cuda:7\n",
            "model.layers.22.self_attn.k_proj.weight: cuda:7\n",
            "model.layers.22.self_attn.v_proj.weight: cuda:7\n",
            "model.layers.22.self_attn.o_proj.weight: cuda:7\n",
            "model.layers.22.self_attn.q_norm.weight: cuda:7\n",
            "model.layers.22.self_attn.k_norm.weight: cuda:7\n",
            "model.layers.22.mlp.gate_proj.weight: cuda:7\n",
            "model.layers.22.mlp.up_proj.weight: cuda:7\n",
            "model.layers.22.mlp.down_proj.weight: cuda:7\n",
            "model.layers.22.input_layernorm.weight: cuda:7\n",
            "model.layers.22.post_attention_layernorm.weight: cuda:7\n",
            "model.layers.23.self_attn.q_proj.weight: cuda:7\n",
            "model.layers.23.self_attn.k_proj.weight: cuda:7\n",
            "model.layers.23.self_attn.v_proj.weight: cuda:7\n",
            "model.layers.23.self_attn.o_proj.weight: cuda:7\n",
            "model.layers.23.self_attn.q_norm.weight: cuda:7\n",
            "model.layers.23.self_attn.k_norm.weight: cuda:7\n",
            "model.layers.23.mlp.gate_proj.weight: cuda:7\n",
            "model.layers.23.mlp.up_proj.weight: cuda:7\n",
            "model.layers.23.mlp.down_proj.weight: cuda:7\n",
            "model.layers.23.input_layernorm.weight: cuda:7\n",
            "model.layers.23.post_attention_layernorm.weight: cuda:7\n",
            "model.layers.24.self_attn.q_proj.weight: cuda:7\n",
            "model.layers.24.self_attn.k_proj.weight: cuda:7\n",
            "model.layers.24.self_attn.v_proj.weight: cuda:7\n",
            "model.layers.24.self_attn.o_proj.weight: cuda:7\n",
            "model.layers.24.self_attn.q_norm.weight: cuda:7\n",
            "model.layers.24.self_attn.k_norm.weight: cuda:7\n",
            "model.layers.24.mlp.gate_proj.weight: cuda:7\n",
            "model.layers.24.mlp.up_proj.weight: cuda:7\n",
            "model.layers.24.mlp.down_proj.weight: cuda:7\n",
            "model.layers.24.input_layernorm.weight: cuda:7\n",
            "model.layers.24.post_attention_layernorm.weight: cuda:7\n",
            "model.layers.25.self_attn.q_proj.weight: cuda:7\n",
            "model.layers.25.self_attn.k_proj.weight: cuda:7\n",
            "model.layers.25.self_attn.v_proj.weight: cuda:7\n",
            "model.layers.25.self_attn.o_proj.weight: cuda:7\n",
            "model.layers.25.self_attn.q_norm.weight: cuda:7\n",
            "model.layers.25.self_attn.k_norm.weight: cuda:7\n",
            "model.layers.25.mlp.gate_proj.weight: cuda:7\n",
            "model.layers.25.mlp.up_proj.weight: cuda:7\n",
            "model.layers.25.mlp.down_proj.weight: cuda:7\n",
            "model.layers.25.input_layernorm.weight: cuda:7\n",
            "model.layers.25.post_attention_layernorm.weight: cuda:7\n",
            "model.layers.26.self_attn.q_proj.weight: cuda:7\n",
            "model.layers.26.self_attn.k_proj.weight: cuda:7\n",
            "model.layers.26.self_attn.v_proj.weight: cuda:7\n",
            "model.layers.26.self_attn.o_proj.weight: cuda:7\n",
            "model.layers.26.self_attn.q_norm.weight: cuda:7\n",
            "model.layers.26.self_attn.k_norm.weight: cuda:7\n",
            "model.layers.26.mlp.gate_proj.weight: cuda:7\n",
            "model.layers.26.mlp.up_proj.weight: cuda:7\n",
            "model.layers.26.mlp.down_proj.weight: cuda:7\n",
            "model.layers.26.input_layernorm.weight: cuda:7\n",
            "model.layers.26.post_attention_layernorm.weight: cuda:7\n",
            "model.layers.27.self_attn.q_proj.weight: cuda:7\n",
            "model.layers.27.self_attn.k_proj.weight: cuda:7\n",
            "model.layers.27.self_attn.v_proj.weight: cuda:7\n",
            "model.layers.27.self_attn.o_proj.weight: cuda:7\n",
            "model.layers.27.self_attn.q_norm.weight: cuda:7\n",
            "model.layers.27.self_attn.k_norm.weight: cuda:7\n",
            "model.layers.27.mlp.gate_proj.weight: cuda:7\n",
            "model.layers.27.mlp.up_proj.weight: cuda:7\n",
            "model.layers.27.mlp.down_proj.weight: cuda:7\n",
            "model.layers.27.input_layernorm.weight: cuda:7\n",
            "model.layers.27.post_attention_layernorm.weight: cuda:7\n",
            "model.norm.weight: cuda:7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset, concatenate_datasets\n",
        "from datasets import Dataset\n",
        "\n",
        "mixed_data = []\n",
        "\n",
        "dataset = load_dataset('json', data_files='/content/data/head_200.jsonl')\n",
        "# dataset = load_dataset('json', data_files='/content/data/tail_9000.jsonl')\n",
        "\n",
        "dataset = dataset.remove_columns([\"system_prompt\"])\n",
        "\n",
        "# 如果数据量大，可以分割为训练集和测试集\n",
        "dataset = dataset['train'].train_test_split(test_size=0.2)\n",
        "train_dataset = dataset[\"train\"]\n",
        "valid_dataset = dataset[\"test\"]\n",
        "# train_gen_dataset = Dataset.from_list(mixed_data[:8000])\n",
        "# valid_gen_dataset = Dataset.from_list(mixed_data[8000:])\n",
        "\n",
        "# train_dataset = concatenate_datasets([train_dataset, train_gen_dataset])\n",
        "# valid_dataset = concatenate_datasets([valid_dataset, valid_gen_dataset])"
      ],
      "metadata": {
        "id": "A61HXaHFhgCb",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1762669084471,
          "user_tz": -480,
          "elapsed": 608,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "id": "A61HXaHFhgCb",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_function(example):\n",
        "    \"\"\"处理单个样本\"\"\"\n",
        "\n",
        "    input_text = f\"指令: {example['input']}\\n响应: \"\n",
        "    output_text = example[\"output\"]\n",
        "    full_text = input_text + output_text\n",
        "\n",
        "    tokenized_full = tokenizer(\n",
        "        full_text,\n",
        "        max_length=8192,  # 减少最大长度\n",
        "        truncation=False,\n",
        "        padding=False,\n",
        "        return_tensors=None\n",
        "    )\n",
        "\n",
        "    tokenized_input = tokenizer(\n",
        "        input_text,\n",
        "        max_length=4096,\n",
        "        truncation=False,\n",
        "        padding=False,\n",
        "        return_tensors=None\n",
        "    )\n",
        "\n",
        "    input_len = len(tokenized_input[\"input_ids\"])\n",
        "    labels = [-100] * input_len + tokenized_full[\"input_ids\"][input_len:]\n",
        "\n",
        "    return {\n",
        "        \"input_ids\": tokenized_full[\"input_ids\"],\n",
        "        \"attention_mask\": tokenized_full[\"attention_mask\"],\n",
        "        \"labels\": labels\n",
        "    }\n",
        "\n",
        "tokenized_train = train_dataset.map(\n",
        "    preprocess_function,\n",
        "    batched=False,  # 关键：使用非批处理模式\n",
        "    remove_columns=train_dataset.column_names\n",
        ")\n",
        "\n",
        "tokenized_valid = valid_dataset.map(\n",
        "    preprocess_function,\n",
        "    batched=False,  # 关键：使用非批处理模式\n",
        "    remove_columns=valid_dataset.column_names\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81,
          "referenced_widgets": [
            "c63846658a054bc893088511b9161829",
            "8bdc2a805bb14f92909c9baa4e5d5535",
            "fdf055c4a4174b0aa26459fcc39cfed1",
            "f58b32b107ac444ea9d0dd2087f6e7b5",
            "d65d95eece914f1d94da479bb64cbda2",
            "375d5c899e074c8bb3e8f14c1a26e5ac",
            "2d9ae379e311493ca1525c2366a8681e",
            "71344111d2384fd09428311e45b34a49",
            "c268de7078b2430185ab769ebc25c486",
            "2ede2712dc34442197c94945777a6fb7",
            "2c9d82411e4c4e4c8e637d87f19b5b7f",
            "2d33282398fa4d36a6dd3e1a995c919a",
            "7fa70137fe6349d9b3bcdba4dab65d48",
            "5260b76ba00048f8b3bf596081fd9fae",
            "9d696ce0ef064d3a8e1daca7044868bd",
            "3d96b29286274ae3b1a507cdc41b3fdd",
            "e2b231ba87cb47c0a53ca7b9115b3be0",
            "189821e5c61847b082d0d00613d1b7a5",
            "16c3bc2d58df40f49376f547907e22eb",
            "4279ce610f834bb79d9f68e837e85361",
            "7ef20736689940b6bf3e045b5adcdd8a",
            "8d86ef511824487789bfb7ed6bfb3dbd"
          ]
        },
        "id": "VyRfOP2Thjla",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1762669180921,
          "user_tz": -480,
          "elapsed": 2156,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "70c69228-7043-45c5-ae1d-716409531521"
      },
      "id": "VyRfOP2Thjla",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/160 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c63846658a054bc893088511b9161829"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/40 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2d33282398fa4d36a6dd3e1a995c919a"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TrainingArguments\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"/content/models/sfted/qwen3-0.6B\",          # 输出目录\n",
        "    # evaluation_strategy=\"steps\",     # 按步数评估\n",
        "    eval_steps=200,                  # 每200步评估一次\n",
        "    save_strategy=\"steps\",           # 按步数保存\n",
        "    save_steps=500,                  # 每500步保存一次\n",
        "    learning_rate=1e-5,              # 学习率（全参数微调使用较低学习率）\n",
        "    per_device_train_batch_size=1,   # 训练批次大小（根据GPU内存调整）\n",
        "    per_device_eval_batch_size=1,    # 评估批次大小\n",
        "    gradient_accumulation_steps=16,   # 梯度累积（等效批次大小=16）\n",
        "    num_train_epochs=2,              # 训练轮数\n",
        "    weight_decay=0.01,               # 权重衰减\n",
        "    warmup_ratio=0.1,                # 学习率预热比例\n",
        "    logging_steps=50,                # 每50步记录日志\n",
        "    report_to=\"none\",                # 禁用报告\n",
        "    # fp16=True,                       # 混合精度训练\n",
        "    fp16=False,  # 混合精度训练\n",
        "    bf16=False,\n",
        "    tf32=False,\n",
        "    dataloader_num_workers=2,\n",
        "    # 多GPU优化配置\n",
        "    dataloader_pin_memory=True,\n",
        "    gradient_checkpointing=True,     # 梯度检查点节省内存\n",
        "    # load_best_model_at_end=True,     # 训练结束时加载最佳模型\n",
        "    metric_for_best_model=\"eval_loss\",  # 根据验证损失选择最佳模型\n",
        "    greater_is_better=False,         # 损失越低越好\n",
        "    optim=\"paged_adamw_8bit\",  # 使用分页的8-bit AdamW优化器（需bitsandbytes）\n",
        "    max_grad_norm=1.0                # 梯度裁剪\n",
        ")"
      ],
      "metadata": {
        "id": "KUAGuq5bhruZ",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1762669279836,
          "user_tz": -480,
          "elapsed": 772,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "id": "KUAGuq5bhruZ",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import Trainer\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_train,\n",
        "    eval_dataset=tokenized_valid,\n",
        "    # data_collator=data_collator,\n",
        "    tokenizer=tokenizer\n",
        ")\n",
        "# Trainer会自动检测GPU并启用数据并行\n",
        "print(f\"Trainer检测到 {trainer.args.n_gpu} 个GPU\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-KEeLtG6hu5s",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1762669292122,
          "user_tz": -480,
          "elapsed": 572,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "7d6f4eff-8161-4e21-f1ae-fdc941dcb29f"
      },
      "id": "-KEeLtG6hu5s",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trainer检测到 1 个GPU\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2567715863.py:3: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import gc\n",
        "\n",
        "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
        "torch.cuda.empty_cache()\n",
        "gc.collect()\n",
        "\n",
        "trainer.train()\n",
        "\n",
        "save_path = \"/content/models/sfted/qwen3-0.6B\"\n",
        "trainer.save_model(save_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        },
        "id": "UXOIN0ZJhyKO",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1762669410997,
          "user_tz": -480,
          "elapsed": 85678,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "d5ed0b88-15c6-453b-dc56-d1231175c8ab"
      },
      "id": "UXOIN0ZJhyKO",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'bos_token_id': None, 'pad_token_id': 151643}.\n",
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='20' max='20' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [20/20 01:14, Epoch 2/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "def check_gpu_memory_usage():\n",
        "    \"\"\"检查所有GPU卡的内存使用情况\"\"\"\n",
        "\n",
        "    print(\"=== GPU内存使用情况 ===\")\n",
        "    print(f\"可用GPU数量: {torch.cuda.device_count()}\")\n",
        "\n",
        "    for i in range(torch.cuda.device_count()):\n",
        "        # 获取GPU属性\n",
        "        props = torch.cuda.get_device_properties(i)\n",
        "\n",
        "        # 内存使用情况\n",
        "        allocated = torch.cuda.memory_allocated(i) / 1024**3  # GB\n",
        "        reserved = torch.cuda.memory_reserved(i) / 1024**3    # GB\n",
        "        total = props.total_memory / 1024**3                  # GB\n",
        "        free = total - allocated                              # GB\n",
        "\n",
        "        # 使用率\n",
        "        usage_percent = (allocated / total) * 100\n",
        "\n",
        "        print(f\"GPU {i}: {props.name}\")\n",
        "        print(f\"  总内存: {total:.1f} GB\")\n",
        "        print(f\"  已分配: {allocated:.2f} GB ({usage_percent:.1f}%)\")\n",
        "        print(f\"  已保留: {reserved:.2f} GB\")\n",
        "        print(f\"  可用内存: {free:.2f} GB\")\n",
        "\n",
        "        # 检查是否有进程占用\n",
        "        if allocated > 0:\n",
        "            print(f\"  ⚠️ GPU {i} 已被占用\")\n",
        "        else:\n",
        "            print(f\"  ✅ GPU {i} 空闲\")\n",
        "\n",
        "# 运行检查\n",
        "check_gpu_memory_usage()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aY7Gb1pIg8Av",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1762669436783,
          "user_tz": -480,
          "elapsed": 286,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "f3c00b14-9096-4c32-9c22-6bf3762e1961"
      },
      "id": "aY7Gb1pIg8Av",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== GPU内存使用情况 ===\n",
            "可用GPU数量: 8\n",
            "GPU 0: NVIDIA A100-SXM4-40GB\n",
            "  总内存: 39.5 GB\n",
            "  已分配: 1.14 GB (2.9%)\n",
            "  已保留: 11.58 GB\n",
            "  可用内存: 38.35 GB\n",
            "  ⚠️ GPU 0 已被占用\n",
            "GPU 1: NVIDIA A100-SXM4-40GB\n",
            "  总内存: 39.5 GB\n",
            "  已分配: 0.00 GB (0.0%)\n",
            "  已保留: 0.00 GB\n",
            "  可用内存: 39.49 GB\n",
            "  ✅ GPU 1 空闲\n",
            "GPU 2: NVIDIA A100-SXM4-40GB\n",
            "  总内存: 39.5 GB\n",
            "  已分配: 0.00 GB (0.0%)\n",
            "  已保留: 0.00 GB\n",
            "  可用内存: 39.49 GB\n",
            "  ✅ GPU 2 空闲\n",
            "GPU 3: NVIDIA A100-SXM4-40GB\n",
            "  总内存: 39.5 GB\n",
            "  已分配: 0.00 GB (0.0%)\n",
            "  已保留: 0.00 GB\n",
            "  可用内存: 39.49 GB\n",
            "  ✅ GPU 3 空闲\n",
            "GPU 4: NVIDIA A100-SXM4-40GB\n",
            "  总内存: 39.5 GB\n",
            "  已分配: 0.00 GB (0.0%)\n",
            "  已保留: 0.00 GB\n",
            "  可用内存: 39.49 GB\n",
            "  ✅ GPU 4 空闲\n",
            "GPU 5: NVIDIA A100-SXM4-40GB\n",
            "  总内存: 39.5 GB\n",
            "  已分配: 0.00 GB (0.0%)\n",
            "  已保留: 0.00 GB\n",
            "  可用内存: 39.49 GB\n",
            "  ✅ GPU 5 空闲\n",
            "GPU 6: NVIDIA A100-SXM4-40GB\n",
            "  总内存: 39.5 GB\n",
            "  已分配: 0.00 GB (0.0%)\n",
            "  已保留: 0.00 GB\n",
            "  可用内存: 39.49 GB\n",
            "  ✅ GPU 6 空闲\n",
            "GPU 7: NVIDIA A100-SXM4-40GB\n",
            "  总内存: 39.5 GB\n",
            "  已分配: 0.00 GB (0.0%)\n",
            "  已保留: 1.42 GB\n",
            "  可用内存: 39.49 GB\n",
            "  ✅ GPU 7 空闲\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import gc\n",
        "\n",
        "del trainer\n",
        "\n",
        "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
        "torch.cuda.empty_cache()\n",
        "gc.collect()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y7w5gBfahaEt",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1762669440984,
          "user_tz": -480,
          "elapsed": 743,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "686c722f-fa8d-48b5-fa67-3d62692f37ca"
      },
      "id": "y7w5gBfahaEt",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1351"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Sylw5WRhhfgq"
      },
      "id": "Sylw5WRhhfgq",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    },
    "colab": {
      "provenance": [],
      "name": "sft_training",
      "gpuType": "A100"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "c63846658a054bc893088511b9161829": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8bdc2a805bb14f92909c9baa4e5d5535",
              "IPY_MODEL_fdf055c4a4174b0aa26459fcc39cfed1",
              "IPY_MODEL_f58b32b107ac444ea9d0dd2087f6e7b5"
            ],
            "layout": "IPY_MODEL_d65d95eece914f1d94da479bb64cbda2"
          }
        },
        "8bdc2a805bb14f92909c9baa4e5d5535": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_375d5c899e074c8bb3e8f14c1a26e5ac",
            "placeholder": "​",
            "style": "IPY_MODEL_2d9ae379e311493ca1525c2366a8681e",
            "value": "Map: 100%"
          }
        },
        "fdf055c4a4174b0aa26459fcc39cfed1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_71344111d2384fd09428311e45b34a49",
            "max": 160,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c268de7078b2430185ab769ebc25c486",
            "value": 160
          }
        },
        "f58b32b107ac444ea9d0dd2087f6e7b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2ede2712dc34442197c94945777a6fb7",
            "placeholder": "​",
            "style": "IPY_MODEL_2c9d82411e4c4e4c8e637d87f19b5b7f",
            "value": " 160/160 [00:01&lt;00:00, 125.37 examples/s]"
          }
        },
        "d65d95eece914f1d94da479bb64cbda2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "375d5c899e074c8bb3e8f14c1a26e5ac": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2d9ae379e311493ca1525c2366a8681e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "71344111d2384fd09428311e45b34a49": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c268de7078b2430185ab769ebc25c486": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2ede2712dc34442197c94945777a6fb7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2c9d82411e4c4e4c8e637d87f19b5b7f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2d33282398fa4d36a6dd3e1a995c919a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7fa70137fe6349d9b3bcdba4dab65d48",
              "IPY_MODEL_5260b76ba00048f8b3bf596081fd9fae",
              "IPY_MODEL_9d696ce0ef064d3a8e1daca7044868bd"
            ],
            "layout": "IPY_MODEL_3d96b29286274ae3b1a507cdc41b3fdd"
          }
        },
        "7fa70137fe6349d9b3bcdba4dab65d48": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e2b231ba87cb47c0a53ca7b9115b3be0",
            "placeholder": "​",
            "style": "IPY_MODEL_189821e5c61847b082d0d00613d1b7a5",
            "value": "Map: 100%"
          }
        },
        "5260b76ba00048f8b3bf596081fd9fae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_16c3bc2d58df40f49376f547907e22eb",
            "max": 40,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4279ce610f834bb79d9f68e837e85361",
            "value": 40
          }
        },
        "9d696ce0ef064d3a8e1daca7044868bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7ef20736689940b6bf3e045b5adcdd8a",
            "placeholder": "​",
            "style": "IPY_MODEL_8d86ef511824487789bfb7ed6bfb3dbd",
            "value": " 40/40 [00:00&lt;00:00, 112.13 examples/s]"
          }
        },
        "3d96b29286274ae3b1a507cdc41b3fdd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e2b231ba87cb47c0a53ca7b9115b3be0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "189821e5c61847b082d0d00613d1b7a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "16c3bc2d58df40f49376f547907e22eb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4279ce610f834bb79d9f68e837e85361": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7ef20736689940b6bf3e045b5adcdd8a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8d86ef511824487789bfb7ed6bfb3dbd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}