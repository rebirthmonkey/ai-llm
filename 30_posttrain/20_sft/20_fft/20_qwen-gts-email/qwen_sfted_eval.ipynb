{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import gc\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "gc.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C4JcHxwT2mOa",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1762670258584,
          "user_tz": -480,
          "elapsed": 576,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "1ea942fd-6614-4839-def0-5f0e99756f25"
      },
      "id": "C4JcHxwT2mOa",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "90"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
        "\n",
        "save_path = \"/content/models/sfted/qwen3-0.6B\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(save_path)\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(save_path,\n",
        "                                            #  device_map=\"auto\"\n",
        "                                             ).to('cuda:7')"
      ],
      "metadata": {
        "id": "9ES-rjOz56J2",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1762670262399,
          "user_tz": -480,
          "elapsed": 1795,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "id": "9ES-rjOz56J2",
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for name, param in model.named_parameters():\n",
        "    print(f\"{name}: {param.device}\")"
      ],
      "metadata": {
        "id": "o4S1XK7EU8gq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "status": "ok",
          "timestamp": 1762670265133,
          "user_tz": -480,
          "elapsed": 286,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "f5b7bf04-acda-4fd5-f52f-a2b347178afe"
      },
      "id": "o4S1XK7EU8gq",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model.embed_tokens.weight: cuda:7\n",
            "model.layers.0.self_attn.q_proj.weight: cuda:7\n",
            "model.layers.0.self_attn.k_proj.weight: cuda:7\n",
            "model.layers.0.self_attn.v_proj.weight: cuda:7\n",
            "model.layers.0.self_attn.o_proj.weight: cuda:7\n",
            "model.layers.0.self_attn.q_norm.weight: cuda:7\n",
            "model.layers.0.self_attn.k_norm.weight: cuda:7\n",
            "model.layers.0.mlp.gate_proj.weight: cuda:7\n",
            "model.layers.0.mlp.up_proj.weight: cuda:7\n",
            "model.layers.0.mlp.down_proj.weight: cuda:7\n",
            "model.layers.0.input_layernorm.weight: cuda:7\n",
            "model.layers.0.post_attention_layernorm.weight: cuda:7\n",
            "model.layers.1.self_attn.q_proj.weight: cuda:7\n",
            "model.layers.1.self_attn.k_proj.weight: cuda:7\n",
            "model.layers.1.self_attn.v_proj.weight: cuda:7\n",
            "model.layers.1.self_attn.o_proj.weight: cuda:7\n",
            "model.layers.1.self_attn.q_norm.weight: cuda:7\n",
            "model.layers.1.self_attn.k_norm.weight: cuda:7\n",
            "model.layers.1.mlp.gate_proj.weight: cuda:7\n",
            "model.layers.1.mlp.up_proj.weight: cuda:7\n",
            "model.layers.1.mlp.down_proj.weight: cuda:7\n",
            "model.layers.1.input_layernorm.weight: cuda:7\n",
            "model.layers.1.post_attention_layernorm.weight: cuda:7\n",
            "model.layers.2.self_attn.q_proj.weight: cuda:7\n",
            "model.layers.2.self_attn.k_proj.weight: cuda:7\n",
            "model.layers.2.self_attn.v_proj.weight: cuda:7\n",
            "model.layers.2.self_attn.o_proj.weight: cuda:7\n",
            "model.layers.2.self_attn.q_norm.weight: cuda:7\n",
            "model.layers.2.self_attn.k_norm.weight: cuda:7\n",
            "model.layers.2.mlp.gate_proj.weight: cuda:7\n",
            "model.layers.2.mlp.up_proj.weight: cuda:7\n",
            "model.layers.2.mlp.down_proj.weight: cuda:7\n",
            "model.layers.2.input_layernorm.weight: cuda:7\n",
            "model.layers.2.post_attention_layernorm.weight: cuda:7\n",
            "model.layers.3.self_attn.q_proj.weight: cuda:7\n",
            "model.layers.3.self_attn.k_proj.weight: cuda:7\n",
            "model.layers.3.self_attn.v_proj.weight: cuda:7\n",
            "model.layers.3.self_attn.o_proj.weight: cuda:7\n",
            "model.layers.3.self_attn.q_norm.weight: cuda:7\n",
            "model.layers.3.self_attn.k_norm.weight: cuda:7\n",
            "model.layers.3.mlp.gate_proj.weight: cuda:7\n",
            "model.layers.3.mlp.up_proj.weight: cuda:7\n",
            "model.layers.3.mlp.down_proj.weight: cuda:7\n",
            "model.layers.3.input_layernorm.weight: cuda:7\n",
            "model.layers.3.post_attention_layernorm.weight: cuda:7\n",
            "model.layers.4.self_attn.q_proj.weight: cuda:7\n",
            "model.layers.4.self_attn.k_proj.weight: cuda:7\n",
            "model.layers.4.self_attn.v_proj.weight: cuda:7\n",
            "model.layers.4.self_attn.o_proj.weight: cuda:7\n",
            "model.layers.4.self_attn.q_norm.weight: cuda:7\n",
            "model.layers.4.self_attn.k_norm.weight: cuda:7\n",
            "model.layers.4.mlp.gate_proj.weight: cuda:7\n",
            "model.layers.4.mlp.up_proj.weight: cuda:7\n",
            "model.layers.4.mlp.down_proj.weight: cuda:7\n",
            "model.layers.4.input_layernorm.weight: cuda:7\n",
            "model.layers.4.post_attention_layernorm.weight: cuda:7\n",
            "model.layers.5.self_attn.q_proj.weight: cuda:7\n",
            "model.layers.5.self_attn.k_proj.weight: cuda:7\n",
            "model.layers.5.self_attn.v_proj.weight: cuda:7\n",
            "model.layers.5.self_attn.o_proj.weight: cuda:7\n",
            "model.layers.5.self_attn.q_norm.weight: cuda:7\n",
            "model.layers.5.self_attn.k_norm.weight: cuda:7\n",
            "model.layers.5.mlp.gate_proj.weight: cuda:7\n",
            "model.layers.5.mlp.up_proj.weight: cuda:7\n",
            "model.layers.5.mlp.down_proj.weight: cuda:7\n",
            "model.layers.5.input_layernorm.weight: cuda:7\n",
            "model.layers.5.post_attention_layernorm.weight: cuda:7\n",
            "model.layers.6.self_attn.q_proj.weight: cuda:7\n",
            "model.layers.6.self_attn.k_proj.weight: cuda:7\n",
            "model.layers.6.self_attn.v_proj.weight: cuda:7\n",
            "model.layers.6.self_attn.o_proj.weight: cuda:7\n",
            "model.layers.6.self_attn.q_norm.weight: cuda:7\n",
            "model.layers.6.self_attn.k_norm.weight: cuda:7\n",
            "model.layers.6.mlp.gate_proj.weight: cuda:7\n",
            "model.layers.6.mlp.up_proj.weight: cuda:7\n",
            "model.layers.6.mlp.down_proj.weight: cuda:7\n",
            "model.layers.6.input_layernorm.weight: cuda:7\n",
            "model.layers.6.post_attention_layernorm.weight: cuda:7\n",
            "model.layers.7.self_attn.q_proj.weight: cuda:7\n",
            "model.layers.7.self_attn.k_proj.weight: cuda:7\n",
            "model.layers.7.self_attn.v_proj.weight: cuda:7\n",
            "model.layers.7.self_attn.o_proj.weight: cuda:7\n",
            "model.layers.7.self_attn.q_norm.weight: cuda:7\n",
            "model.layers.7.self_attn.k_norm.weight: cuda:7\n",
            "model.layers.7.mlp.gate_proj.weight: cuda:7\n",
            "model.layers.7.mlp.up_proj.weight: cuda:7\n",
            "model.layers.7.mlp.down_proj.weight: cuda:7\n",
            "model.layers.7.input_layernorm.weight: cuda:7\n",
            "model.layers.7.post_attention_layernorm.weight: cuda:7\n",
            "model.layers.8.self_attn.q_proj.weight: cuda:7\n",
            "model.layers.8.self_attn.k_proj.weight: cuda:7\n",
            "model.layers.8.self_attn.v_proj.weight: cuda:7\n",
            "model.layers.8.self_attn.o_proj.weight: cuda:7\n",
            "model.layers.8.self_attn.q_norm.weight: cuda:7\n",
            "model.layers.8.self_attn.k_norm.weight: cuda:7\n",
            "model.layers.8.mlp.gate_proj.weight: cuda:7\n",
            "model.layers.8.mlp.up_proj.weight: cuda:7\n",
            "model.layers.8.mlp.down_proj.weight: cuda:7\n",
            "model.layers.8.input_layernorm.weight: cuda:7\n",
            "model.layers.8.post_attention_layernorm.weight: cuda:7\n",
            "model.layers.9.self_attn.q_proj.weight: cuda:7\n",
            "model.layers.9.self_attn.k_proj.weight: cuda:7\n",
            "model.layers.9.self_attn.v_proj.weight: cuda:7\n",
            "model.layers.9.self_attn.o_proj.weight: cuda:7\n",
            "model.layers.9.self_attn.q_norm.weight: cuda:7\n",
            "model.layers.9.self_attn.k_norm.weight: cuda:7\n",
            "model.layers.9.mlp.gate_proj.weight: cuda:7\n",
            "model.layers.9.mlp.up_proj.weight: cuda:7\n",
            "model.layers.9.mlp.down_proj.weight: cuda:7\n",
            "model.layers.9.input_layernorm.weight: cuda:7\n",
            "model.layers.9.post_attention_layernorm.weight: cuda:7\n",
            "model.layers.10.self_attn.q_proj.weight: cuda:7\n",
            "model.layers.10.self_attn.k_proj.weight: cuda:7\n",
            "model.layers.10.self_attn.v_proj.weight: cuda:7\n",
            "model.layers.10.self_attn.o_proj.weight: cuda:7\n",
            "model.layers.10.self_attn.q_norm.weight: cuda:7\n",
            "model.layers.10.self_attn.k_norm.weight: cuda:7\n",
            "model.layers.10.mlp.gate_proj.weight: cuda:7\n",
            "model.layers.10.mlp.up_proj.weight: cuda:7\n",
            "model.layers.10.mlp.down_proj.weight: cuda:7\n",
            "model.layers.10.input_layernorm.weight: cuda:7\n",
            "model.layers.10.post_attention_layernorm.weight: cuda:7\n",
            "model.layers.11.self_attn.q_proj.weight: cuda:7\n",
            "model.layers.11.self_attn.k_proj.weight: cuda:7\n",
            "model.layers.11.self_attn.v_proj.weight: cuda:7\n",
            "model.layers.11.self_attn.o_proj.weight: cuda:7\n",
            "model.layers.11.self_attn.q_norm.weight: cuda:7\n",
            "model.layers.11.self_attn.k_norm.weight: cuda:7\n",
            "model.layers.11.mlp.gate_proj.weight: cuda:7\n",
            "model.layers.11.mlp.up_proj.weight: cuda:7\n",
            "model.layers.11.mlp.down_proj.weight: cuda:7\n",
            "model.layers.11.input_layernorm.weight: cuda:7\n",
            "model.layers.11.post_attention_layernorm.weight: cuda:7\n",
            "model.layers.12.self_attn.q_proj.weight: cuda:7\n",
            "model.layers.12.self_attn.k_proj.weight: cuda:7\n",
            "model.layers.12.self_attn.v_proj.weight: cuda:7\n",
            "model.layers.12.self_attn.o_proj.weight: cuda:7\n",
            "model.layers.12.self_attn.q_norm.weight: cuda:7\n",
            "model.layers.12.self_attn.k_norm.weight: cuda:7\n",
            "model.layers.12.mlp.gate_proj.weight: cuda:7\n",
            "model.layers.12.mlp.up_proj.weight: cuda:7\n",
            "model.layers.12.mlp.down_proj.weight: cuda:7\n",
            "model.layers.12.input_layernorm.weight: cuda:7\n",
            "model.layers.12.post_attention_layernorm.weight: cuda:7\n",
            "model.layers.13.self_attn.q_proj.weight: cuda:7\n",
            "model.layers.13.self_attn.k_proj.weight: cuda:7\n",
            "model.layers.13.self_attn.v_proj.weight: cuda:7\n",
            "model.layers.13.self_attn.o_proj.weight: cuda:7\n",
            "model.layers.13.self_attn.q_norm.weight: cuda:7\n",
            "model.layers.13.self_attn.k_norm.weight: cuda:7\n",
            "model.layers.13.mlp.gate_proj.weight: cuda:7\n",
            "model.layers.13.mlp.up_proj.weight: cuda:7\n",
            "model.layers.13.mlp.down_proj.weight: cuda:7\n",
            "model.layers.13.input_layernorm.weight: cuda:7\n",
            "model.layers.13.post_attention_layernorm.weight: cuda:7\n",
            "model.layers.14.self_attn.q_proj.weight: cuda:7\n",
            "model.layers.14.self_attn.k_proj.weight: cuda:7\n",
            "model.layers.14.self_attn.v_proj.weight: cuda:7\n",
            "model.layers.14.self_attn.o_proj.weight: cuda:7\n",
            "model.layers.14.self_attn.q_norm.weight: cuda:7\n",
            "model.layers.14.self_attn.k_norm.weight: cuda:7\n",
            "model.layers.14.mlp.gate_proj.weight: cuda:7\n",
            "model.layers.14.mlp.up_proj.weight: cuda:7\n",
            "model.layers.14.mlp.down_proj.weight: cuda:7\n",
            "model.layers.14.input_layernorm.weight: cuda:7\n",
            "model.layers.14.post_attention_layernorm.weight: cuda:7\n",
            "model.layers.15.self_attn.q_proj.weight: cuda:7\n",
            "model.layers.15.self_attn.k_proj.weight: cuda:7\n",
            "model.layers.15.self_attn.v_proj.weight: cuda:7\n",
            "model.layers.15.self_attn.o_proj.weight: cuda:7\n",
            "model.layers.15.self_attn.q_norm.weight: cuda:7\n",
            "model.layers.15.self_attn.k_norm.weight: cuda:7\n",
            "model.layers.15.mlp.gate_proj.weight: cuda:7\n",
            "model.layers.15.mlp.up_proj.weight: cuda:7\n",
            "model.layers.15.mlp.down_proj.weight: cuda:7\n",
            "model.layers.15.input_layernorm.weight: cuda:7\n",
            "model.layers.15.post_attention_layernorm.weight: cuda:7\n",
            "model.layers.16.self_attn.q_proj.weight: cuda:7\n",
            "model.layers.16.self_attn.k_proj.weight: cuda:7\n",
            "model.layers.16.self_attn.v_proj.weight: cuda:7\n",
            "model.layers.16.self_attn.o_proj.weight: cuda:7\n",
            "model.layers.16.self_attn.q_norm.weight: cuda:7\n",
            "model.layers.16.self_attn.k_norm.weight: cuda:7\n",
            "model.layers.16.mlp.gate_proj.weight: cuda:7\n",
            "model.layers.16.mlp.up_proj.weight: cuda:7\n",
            "model.layers.16.mlp.down_proj.weight: cuda:7\n",
            "model.layers.16.input_layernorm.weight: cuda:7\n",
            "model.layers.16.post_attention_layernorm.weight: cuda:7\n",
            "model.layers.17.self_attn.q_proj.weight: cuda:7\n",
            "model.layers.17.self_attn.k_proj.weight: cuda:7\n",
            "model.layers.17.self_attn.v_proj.weight: cuda:7\n",
            "model.layers.17.self_attn.o_proj.weight: cuda:7\n",
            "model.layers.17.self_attn.q_norm.weight: cuda:7\n",
            "model.layers.17.self_attn.k_norm.weight: cuda:7\n",
            "model.layers.17.mlp.gate_proj.weight: cuda:7\n",
            "model.layers.17.mlp.up_proj.weight: cuda:7\n",
            "model.layers.17.mlp.down_proj.weight: cuda:7\n",
            "model.layers.17.input_layernorm.weight: cuda:7\n",
            "model.layers.17.post_attention_layernorm.weight: cuda:7\n",
            "model.layers.18.self_attn.q_proj.weight: cuda:7\n",
            "model.layers.18.self_attn.k_proj.weight: cuda:7\n",
            "model.layers.18.self_attn.v_proj.weight: cuda:7\n",
            "model.layers.18.self_attn.o_proj.weight: cuda:7\n",
            "model.layers.18.self_attn.q_norm.weight: cuda:7\n",
            "model.layers.18.self_attn.k_norm.weight: cuda:7\n",
            "model.layers.18.mlp.gate_proj.weight: cuda:7\n",
            "model.layers.18.mlp.up_proj.weight: cuda:7\n",
            "model.layers.18.mlp.down_proj.weight: cuda:7\n",
            "model.layers.18.input_layernorm.weight: cuda:7\n",
            "model.layers.18.post_attention_layernorm.weight: cuda:7\n",
            "model.layers.19.self_attn.q_proj.weight: cuda:7\n",
            "model.layers.19.self_attn.k_proj.weight: cuda:7\n",
            "model.layers.19.self_attn.v_proj.weight: cuda:7\n",
            "model.layers.19.self_attn.o_proj.weight: cuda:7\n",
            "model.layers.19.self_attn.q_norm.weight: cuda:7\n",
            "model.layers.19.self_attn.k_norm.weight: cuda:7\n",
            "model.layers.19.mlp.gate_proj.weight: cuda:7\n",
            "model.layers.19.mlp.up_proj.weight: cuda:7\n",
            "model.layers.19.mlp.down_proj.weight: cuda:7\n",
            "model.layers.19.input_layernorm.weight: cuda:7\n",
            "model.layers.19.post_attention_layernorm.weight: cuda:7\n",
            "model.layers.20.self_attn.q_proj.weight: cuda:7\n",
            "model.layers.20.self_attn.k_proj.weight: cuda:7\n",
            "model.layers.20.self_attn.v_proj.weight: cuda:7\n",
            "model.layers.20.self_attn.o_proj.weight: cuda:7\n",
            "model.layers.20.self_attn.q_norm.weight: cuda:7\n",
            "model.layers.20.self_attn.k_norm.weight: cuda:7\n",
            "model.layers.20.mlp.gate_proj.weight: cuda:7\n",
            "model.layers.20.mlp.up_proj.weight: cuda:7\n",
            "model.layers.20.mlp.down_proj.weight: cuda:7\n",
            "model.layers.20.input_layernorm.weight: cuda:7\n",
            "model.layers.20.post_attention_layernorm.weight: cuda:7\n",
            "model.layers.21.self_attn.q_proj.weight: cuda:7\n",
            "model.layers.21.self_attn.k_proj.weight: cuda:7\n",
            "model.layers.21.self_attn.v_proj.weight: cuda:7\n",
            "model.layers.21.self_attn.o_proj.weight: cuda:7\n",
            "model.layers.21.self_attn.q_norm.weight: cuda:7\n",
            "model.layers.21.self_attn.k_norm.weight: cuda:7\n",
            "model.layers.21.mlp.gate_proj.weight: cuda:7\n",
            "model.layers.21.mlp.up_proj.weight: cuda:7\n",
            "model.layers.21.mlp.down_proj.weight: cuda:7\n",
            "model.layers.21.input_layernorm.weight: cuda:7\n",
            "model.layers.21.post_attention_layernorm.weight: cuda:7\n",
            "model.layers.22.self_attn.q_proj.weight: cuda:7\n",
            "model.layers.22.self_attn.k_proj.weight: cuda:7\n",
            "model.layers.22.self_attn.v_proj.weight: cuda:7\n",
            "model.layers.22.self_attn.o_proj.weight: cuda:7\n",
            "model.layers.22.self_attn.q_norm.weight: cuda:7\n",
            "model.layers.22.self_attn.k_norm.weight: cuda:7\n",
            "model.layers.22.mlp.gate_proj.weight: cuda:7\n",
            "model.layers.22.mlp.up_proj.weight: cuda:7\n",
            "model.layers.22.mlp.down_proj.weight: cuda:7\n",
            "model.layers.22.input_layernorm.weight: cuda:7\n",
            "model.layers.22.post_attention_layernorm.weight: cuda:7\n",
            "model.layers.23.self_attn.q_proj.weight: cuda:7\n",
            "model.layers.23.self_attn.k_proj.weight: cuda:7\n",
            "model.layers.23.self_attn.v_proj.weight: cuda:7\n",
            "model.layers.23.self_attn.o_proj.weight: cuda:7\n",
            "model.layers.23.self_attn.q_norm.weight: cuda:7\n",
            "model.layers.23.self_attn.k_norm.weight: cuda:7\n",
            "model.layers.23.mlp.gate_proj.weight: cuda:7\n",
            "model.layers.23.mlp.up_proj.weight: cuda:7\n",
            "model.layers.23.mlp.down_proj.weight: cuda:7\n",
            "model.layers.23.input_layernorm.weight: cuda:7\n",
            "model.layers.23.post_attention_layernorm.weight: cuda:7\n",
            "model.layers.24.self_attn.q_proj.weight: cuda:7\n",
            "model.layers.24.self_attn.k_proj.weight: cuda:7\n",
            "model.layers.24.self_attn.v_proj.weight: cuda:7\n",
            "model.layers.24.self_attn.o_proj.weight: cuda:7\n",
            "model.layers.24.self_attn.q_norm.weight: cuda:7\n",
            "model.layers.24.self_attn.k_norm.weight: cuda:7\n",
            "model.layers.24.mlp.gate_proj.weight: cuda:7\n",
            "model.layers.24.mlp.up_proj.weight: cuda:7\n",
            "model.layers.24.mlp.down_proj.weight: cuda:7\n",
            "model.layers.24.input_layernorm.weight: cuda:7\n",
            "model.layers.24.post_attention_layernorm.weight: cuda:7\n",
            "model.layers.25.self_attn.q_proj.weight: cuda:7\n",
            "model.layers.25.self_attn.k_proj.weight: cuda:7\n",
            "model.layers.25.self_attn.v_proj.weight: cuda:7\n",
            "model.layers.25.self_attn.o_proj.weight: cuda:7\n",
            "model.layers.25.self_attn.q_norm.weight: cuda:7\n",
            "model.layers.25.self_attn.k_norm.weight: cuda:7\n",
            "model.layers.25.mlp.gate_proj.weight: cuda:7\n",
            "model.layers.25.mlp.up_proj.weight: cuda:7\n",
            "model.layers.25.mlp.down_proj.weight: cuda:7\n",
            "model.layers.25.input_layernorm.weight: cuda:7\n",
            "model.layers.25.post_attention_layernorm.weight: cuda:7\n",
            "model.layers.26.self_attn.q_proj.weight: cuda:7\n",
            "model.layers.26.self_attn.k_proj.weight: cuda:7\n",
            "model.layers.26.self_attn.v_proj.weight: cuda:7\n",
            "model.layers.26.self_attn.o_proj.weight: cuda:7\n",
            "model.layers.26.self_attn.q_norm.weight: cuda:7\n",
            "model.layers.26.self_attn.k_norm.weight: cuda:7\n",
            "model.layers.26.mlp.gate_proj.weight: cuda:7\n",
            "model.layers.26.mlp.up_proj.weight: cuda:7\n",
            "model.layers.26.mlp.down_proj.weight: cuda:7\n",
            "model.layers.26.input_layernorm.weight: cuda:7\n",
            "model.layers.26.post_attention_layernorm.weight: cuda:7\n",
            "model.layers.27.self_attn.q_proj.weight: cuda:7\n",
            "model.layers.27.self_attn.k_proj.weight: cuda:7\n",
            "model.layers.27.self_attn.v_proj.weight: cuda:7\n",
            "model.layers.27.self_attn.o_proj.weight: cuda:7\n",
            "model.layers.27.self_attn.q_norm.weight: cuda:7\n",
            "model.layers.27.self_attn.k_norm.weight: cuda:7\n",
            "model.layers.27.mlp.gate_proj.weight: cuda:7\n",
            "model.layers.27.mlp.up_proj.weight: cuda:7\n",
            "model.layers.27.mlp.down_proj.weight: cuda:7\n",
            "model.layers.27.input_layernorm.weight: cuda:7\n",
            "model.layers.27.post_attention_layernorm.weight: cuda:7\n",
            "model.norm.weight: cuda:7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y3xLJR42Kfab",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1762670269802,
          "user_tz": -480,
          "elapsed": 2,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "57b036f2-b715-48af-bc20-fee939f24078"
      },
      "id": "Y3xLJR42Kfab",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda', index=7)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare prompt\n",
        "\n",
        "prompt_template = \"\"\"\n",
        "Output in JSON format. Output must only include the JSON object text (no markdown fences, no extra explanation).\n",
        "\n",
        "Analyze the provided email sent to Tencent Cloud about infringement complaints, and extract relevant details to populate the structured format below.\n",
        "Read the mail content to generate the summary.\n",
        "\n",
        "The JSON schema is:\n",
        "\n",
        "{{\n",
        "  \"incident_id\": \"Extract the incident ID from the complaint, if present. Omit this field if not applicable.\",\n",
        "  \"eff_sender_name\": \"Identify and provide the original sender's name if the email appears to be forwarded. Omit this field otherwise.\",\n",
        "  \"eff_sender_mail\": \"Provide the original sender's email address if the email appears to be forwarded. Omit this field otherwise.\",\n",
        "  \"eff_sent_time\": \"Include the sent time of the original email, converted to Beijing time in the format 'YYYY-MM-DD HH:MM:SS', if the email appears to be forwarded. Omit this field otherwise.\",\n",
        "  \"summary\": \"Summarize the main complaint of the email, including the main points of the complaint and the requested actions. Include any relevant details about the complaint. Omit this field if the email is not a complaint.\",\n",
        "  \"summary_zh\": \"Translate the summary into Chinese.\",\n",
        "  \"infringe_ips\": \"List IP addresses that are accused of infringement, separated by commas. Omit this field if there are no IPs mentioned.\",\n",
        "  \"infringe_domains\": \"List domain names accused of infringing on copyright, separated by commas. These domains, if they exist, should be a part of the infringing URLs mentioned in the mail.\",\n",
        "  \"infringed_domains\": \"List domain names that hold the copyrighted content which is claimed to be infringed upon, separated by commas if multiple. Use this field for domains that are victims of copyright infringement.\",\n",
        "  \"copyright_owner\": \"Provide the name of the copyright owner or the infringed party. Use abbreviations if possible, set to \\\"Unknown\\\" if not mentioned in the mail.\",\n",
        "  \"spam\": \"Mark this field as true if the email is obviously not related to infringement, such as spam or marketing emails. Omit this field if the email is related to infringement.\",\n",
        "  \"contact_email\": \"If a contact or reporter email is provided in the email, include it here. Omit this field if not applicable.\"\n",
        "}}\n",
        "\n",
        "Now here is the email to analyze:\n",
        "\n",
        "{input_text}\n",
        "\"\"\"\n",
        "\n",
        "input_text = \"\"\"\n",
        "Subject: Urgent Copyright Infringement Notice - Incident ID 8888888 - Urgent live stream escalation for URL http://play1nm.aaaa.cn/live/ballbar_24690-1715195519.ts - The Union of European Football Associations (UEFA) - 11.11.11.11\n",
        "\n",
        "Content:\n",
        "\n",
        "**发件人:** bounce-md_30134155.663be85b.v1-08d5422e6de84195ad22066429622b97@mail.bbb.com代表Friend MTS\n",
        "**已发送:** 2024年5月9日 5:02:19 (UTC+08:00)北京，重庆，香港特别行政区，乌鲁木齐\n",
        "**收件人:** XXX_net_duty(CNOC值班帐户)\n",
        "**抄送:** operations@bbb.com\n",
        "**主题:** [Internet]Urgent Copyright Infringement Notice - Incident ID 8888888 - Urgent live stream escalation for URL http://play1nm.aaaa.cn/live/ballbar_24690-1715195519.ts - The Union of European Football Associations (UEFA) - 11.11.11.11\n",
        "\n",
        "Dear Sir/Madam,\n",
        "\n",
        "Please find below a copyright infringement notice sent to a site that is making use of streaming servers hosted within your infrastructure. The technical parameters for the stream are as follows, to enable you to trace the specific machine within your infrastructure.\n",
        "\n",
        "ip address: 11.11.11.11\n",
        "tcUrl: http://play1nm.aaaa.cn/live/ballbar_24690-1715195519.ts\n",
        "Playpath:\n",
        "pageUrl: http://play1nm.aaaa.cn/live/ballbar_24690-1715195519.ts\n",
        "swfUrl:\n",
        "\n",
        "We appreciate that the site itself may be hosted separately, and the domain may no longer resolve to one of your IP addresses, however at the time quoted we captured the stream from a stream server at the indicated IP address and current best information resolves this address to yourselves.\n",
        "Please disable access to all such unauthorized materials of the copyright owner/holder and cease display and distribution immediately, via all means, of all proprietary materials of The Union of European Football Associations (UEFA).\n",
        "\n",
        "Kind regards\n",
        "\n",
        "ccc DDD\n",
        "\n",
        "DDD MTS Limited\n",
        "Email: uefamonitoring@bbb.com\n",
        "\n",
        "---------- Forwarded Message ----------\n",
        "\n",
        "Subject: Urgent Copyright Infringement Notice - The Union of European Football Associations (UEFA): Incident ID 8888888\n",
        "Date: 2024-05-08 19:27:16\n",
        "\n",
        "Dear Sir/Madam,\n",
        "\n",
        "I am writing to you on behalf of our client, The Union of European Football Associations (UEFA).\n",
        "\n",
        "Through our monitoring programme we have become aware that, on your website play1nm.aaaa.cn, there is copyrighted programming, images and/or hyperlinks, found through the following URL(s)/Channel(s):\n",
        "\n",
        "URL: http://play1nm.aaaa.cn/live/ballbar_24690.m3u8\n",
        "Incident ID: 8888888\n",
        "Date seen (UTC): 2024-05-08 19:27:16\n",
        "\n",
        "Your actions are an infringement of our client's rights; in particular they constitute copyright infringement under applicable legislation, including that relating to apparatus used for unauthorised reception of transmissions or to online service providers. As a result, your use of our client's copyright protected material is likely to divert custom from our client.\n",
        "\n",
        "Our client takes infringement of their rights in this way very seriously. This is a serious matter causing, or likely to cause, significant loss to our client, and our client therefore requires that you immediately cease all such infringing and unlawful activity.\n",
        "\n",
        "We hereby state that we have a good faith belief that the disputed use of the copyrighted material is not authorised by the copyright owner, its agent, or the law (e.g. as a fair use).\n",
        "\n",
        "We hereby state that the information in this Notice is accurate and, under penalty of perjury, that our client is the owner, or authorised to act on behalf of the owner, of the copyright or of an exclusive right under the copyright that is allegedly infringed.\n",
        "\n",
        "In the circumstances, our client requires you to remove the channels complained about immediately.\n",
        "\n",
        "Our client reserves all of their rights in this matter.\n",
        "\n",
        "Please confirm within 10 minutes by email to uefamonitoring@bbb.com, retaining our Incident ID in the subject line, that you have complied with the above.\n",
        "\n",
        "Yours sincerely,\n",
        "\n",
        "ccc DDD\n",
        "\n",
        "DDD MTS Limited\n",
        "\n",
        "\n",
        "Email: uefamonitoring@bbb.com\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "id": "fTFBdqg4TQ1m",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1762670272264,
          "user_tz": -480,
          "elapsed": 2,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "id": "fTFBdqg4TQ1m",
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "messages = [\n",
        "    {\"role\": \"user\", \"content\": prompt_template.format(input_text=input_text)}\n",
        "]\n",
        "\n",
        "formatted_messages = tokenizer.apply_chat_template(\n",
        "    messages,\n",
        "    tokenize=False,\n",
        "    add_generation_prompt=True,\n",
        "    enable_thinking=False # Switches between thinking and non-thinking modes. Default is True.\n",
        ")\n",
        "\n",
        "tokenized_messages = tokenizer([formatted_messages], return_tensors=\"pt\").to(model.device)\n",
        "\n",
        "# conduct text completion\n",
        "import time\n",
        "start_time = time.time()\n",
        "\n",
        "generated_ids = model.generate(\n",
        "    **tokenized_messages,\n",
        "    max_new_tokens=32768\n",
        ")\n",
        "\n",
        "output_ids = generated_ids[0][len(tokenized_messages.input_ids[0]):].tolist()\n",
        "\n",
        "end_time = time.time()\n",
        "execution_time_minutes = (end_time - start_time) / 60\n",
        "print(f\"Generating completed in {execution_time_minutes:.2f} minutes.\")\n",
        "\n",
        "# parsing thinking content\n",
        "try:\n",
        "    # rindex finding 151668 (</think>)\n",
        "    index = len(output_ids) - output_ids[::-1].index(151668)\n",
        "except ValueError:\n",
        "    index = 0\n",
        "\n",
        "thinking_content = tokenizer.decode(output_ids[:index], skip_special_tokens=True).strip(\"\\n\")\n",
        "content = tokenizer.decode(output_ids[index:], skip_special_tokens=True).strip(\"\\n\")\n",
        "\n",
        "print(\"thinking content:\", thinking_content)\n",
        "print(\"content:\", content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ow-eGQEL6LVa",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1762670293474,
          "user_tz": -480,
          "elapsed": 18066,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "e73e8493-147e-4686-b635-891c758cf14d"
      },
      "id": "Ow-eGQEL6LVa",
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating completed in 0.30 minutes.\n",
            "thinking content: \n",
            "content: {\n",
            "  \"incident_id\": \"8888888\",\n",
            "  \"eff_sender_name\": \"Friend MTS\",\n",
            "  \"eff_sender_mail\": \"bounce-md_30134155.663be85b.v1-08d5422e6de84195ad22066429622b97@mail.bbb.com\",\n",
            "  \"eff_sent_time\": \"2024-05-08 19:27:19+00\",\n",
            "  \"summary\": \"The email is a copyright infringement notice sent on behalf of The Union of European Football Associations (UEFA) regarding unauthorized streaming of copyrighted programming, images, and/or hyperlinks on the website play1nm.aaaa.cn. The notice requests immediate cessation of infringing and unlawful activity and states that the copyright owner or their agent is the one responsible for the alleged infringement.\\nDomain(s) mentioned in the mail: aaaa.cn,play1nm.aaaa.cn.IP(s) mentioned in the mail: 11.11.11.11.\",\n",
            "  \"summary_zh\": \"这封电子邮件是代表欧洲足球协会（UEFA）发送的版权侵权通知，关于在网站play1nm.aaaa.cn上非法播放受版权保护的节目、图片和/或超链接。通知要求立即停止侵权和非法活动，并声明版权人或其代理人是负责侵权的。\\n邮件中提及的域名: aaaa.cn,play1nm.aaaa.cn。邮件中提及的IP: 11.11.11.11。\",\n",
            "  \"infringe_ips\": \"11.11.11.11\",\n",
            "  \"infringe_domains\": \"aaaa.cn\",\n",
            "  \"infringed_domains\": \"play1nm.aaaa.cn\",\n",
            "  \"copyright_owner\": \"The Union of European Football Associations (UEFA)\",\n",
            "  \"spam\": \"False\"\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yr16nDzbUjRY"
      },
      "id": "yr16nDzbUjRY",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    },
    "colab": {
      "provenance": [],
      "name": "sfted_model_eval",
      "gpuType": "A100"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}