{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "593cd04b",
   "metadata": {},
   "source": [
    "# GPT2 SFT for Instructions\n",
    "\n",
    "## Dataset Preparation\n",
    "\n",
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "18299e85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of entries: 1100\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import urllib\n",
    "\n",
    "\n",
    "def download_and_load_file(file_path, url):\n",
    "\n",
    "    if not os.path.exists(file_path):\n",
    "        with urllib.request.urlopen(url) as response:\n",
    "            text_data = response.read().decode(\"utf-8\")\n",
    "        with open(file_path, \"w\", encoding=\"utf-8\") as file:\n",
    "            file.write(text_data)\n",
    "\n",
    "    # The book originally contained this unnecessary \"else\" clause:\n",
    "    #else:\n",
    "    #    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "    #        text_data = file.read()\n",
    "\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "        data = json.load(file)\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "file_path = \"instruction-data.json\"\n",
    "url = (\n",
    "    \"https://raw.githubusercontent.com/rasbt/LLMs-from-scratch\"\n",
    "    \"/main/ch07/01_main-chapter-code/instruction-data.json\"\n",
    ")\n",
    "\n",
    "data = download_and_load_file(file_path, url)\n",
    "print(\"Number of entries:\", len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "683ca255",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example entry:\n",
      " {'instruction': 'Identify the correct spelling of the following word.', 'input': 'Ocassion', 'output': \"The correct spelling is 'Occasion.'\"}\n"
     ]
    }
   ],
   "source": [
    "print(\"Example entry:\\n\", data[50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3d2384e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Another example entry:\n",
      " {'instruction': \"What is an antonym of 'complicated'?\", 'input': '', 'output': \"An antonym of 'complicated' is 'simple'.\"}\n"
     ]
    }
   ],
   "source": [
    "print(\"Another example entry:\\n\", data[999])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0087bc6",
   "metadata": {},
   "source": [
    "### Input Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2fe5ffb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Identify the correct spelling of the following word.\n",
      "\n",
      "### Input:\n",
      "Ocassion\n",
      "\n",
      "### Response:\n",
      "The correct spelling is 'Occasion.'\n"
     ]
    }
   ],
   "source": [
    "def format_input(entry):\n",
    "    instruction_text = (\n",
    "        f\"Below is an instruction that describes a task. \"\n",
    "        f\"Write a response that appropriately completes the request.\"\n",
    "        f\"\\n\\n### Instruction:\\n{entry['instruction']}\"\n",
    "    )\n",
    "\n",
    "    input_text = f\"\\n\\n### Input:\\n{entry['input']}\" if entry[\"input\"] else \"\"\n",
    "\n",
    "    return instruction_text + input_text\n",
    "\n",
    "\n",
    "model_input = format_input(data[50])\n",
    "desired_response = f\"\\n\\n### Response:\\n{data[50]['output']}\"\n",
    "\n",
    "print(model_input + desired_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7e15c652",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "What is an antonym of 'complicated'?\n",
      "\n",
      "### Response:\n",
      "An antonym of 'complicated' is 'simple'.\n"
     ]
    }
   ],
   "source": [
    "model_input = format_input(data[999])\n",
    "desired_response = f\"\\n\\n### Response:\\n{data[999]['output']}\"\n",
    "\n",
    "print(model_input + desired_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ede138b1",
   "metadata": {},
   "source": [
    "### Dataset Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4d2eeb79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set length: 935\n",
      "Validation set length: 55\n",
      "Test set length: 110\n"
     ]
    }
   ],
   "source": [
    "train_portion = int(len(data) * 0.85)  # 85% for training\n",
    "test_portion = int(len(data) * 0.1)    # 10% for testing\n",
    "val_portion = len(data) - train_portion - test_portion  # Remaining 5% for validation\n",
    "\n",
    "train_data = data[:train_portion]\n",
    "test_data = data[train_portion:train_portion + test_portion]\n",
    "val_data = data[train_portion + test_portion:]\n",
    "\n",
    "print(\"Training set length:\", len(train_data))\n",
    "print(\"Validation set length:\", len(val_data))\n",
    "print(\"Test set length:\", len(test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b73f4731",
   "metadata": {},
   "source": [
    "### Batch Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "18270388",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "class InstructionDataset(Dataset):\n",
    "    def __init__(self, data, tokenizer):\n",
    "        self.data = data\n",
    "\n",
    "        # Pre-tokenize texts\n",
    "        self.encoded_texts = []\n",
    "        for entry in data:\n",
    "            instruction_plus_input = format_input(entry)\n",
    "            response_text = f\"\\n\\n### Response:\\n{entry['output']}\"\n",
    "            full_text = instruction_plus_input + response_text\n",
    "            self.encoded_texts.append(\n",
    "                tokenizer.encode(full_text)\n",
    "            )\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.encoded_texts[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "64db1948",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50256]\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "print(tokenizer.encode(\"<|endoftext|>\", allowed_special={\"<|endoftext|>\"}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "980b4a93",
   "metadata": {},
   "source": [
    "### Create Targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8b12da8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    0,     1,     2,     3,     4],\n",
      "        [    5,     6, 50256, 50256, 50256],\n",
      "        [    7,     8,     9, 50256, 50256]])\n"
     ]
    }
   ],
   "source": [
    "def custom_collate_draft_1(\n",
    "    batch,\n",
    "    pad_token_id=50256,\n",
    "    device=\"cpu\"\n",
    "):\n",
    "    # Find the longest sequence in the batch\n",
    "    # and increase the max length by +1, which will add one extra\n",
    "    # padding token below\n",
    "    batch_max_length = max(len(item)+1 for item in batch)\n",
    "\n",
    "    # Pad and prepare inputs\n",
    "    inputs_lst = []\n",
    "\n",
    "    for item in batch:\n",
    "        new_item = item.copy()\n",
    "        # Add an <|endoftext|> token\n",
    "        new_item += [pad_token_id]\n",
    "        # Pad sequences to batch_max_length\n",
    "        padded = (\n",
    "            new_item + [pad_token_id] *\n",
    "            (batch_max_length - len(new_item))\n",
    "        )\n",
    "        # Via padded[:-1], we remove the extra padded token\n",
    "        # that has been added via the +1 setting in batch_max_length\n",
    "        # (the extra padding token will be relevant in later codes)\n",
    "        inputs = torch.tensor(padded[:-1])\n",
    "        inputs_lst.append(inputs)\n",
    "\n",
    "    # Convert list of inputs to tensor and transfer to target device\n",
    "    inputs_tensor = torch.stack(inputs_lst).to(device)\n",
    "    return inputs_tensor\n",
    "\n",
    "inputs_1 = [0, 1, 2, 3, 4]\n",
    "inputs_2 = [5, 6]\n",
    "inputs_3 = [7, 8, 9]\n",
    "\n",
    "batch = (\n",
    "    inputs_1,\n",
    "    inputs_2,\n",
    "    inputs_3\n",
    ")\n",
    "\n",
    "print(custom_collate_draft_1(batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cbe7a8a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    0,     1,     2,     3,     4],\n",
      "        [    5,     6, 50256, 50256, 50256],\n",
      "        [    7,     8,     9, 50256, 50256]])\n",
      "tensor([[    1,     2,     3,     4, 50256],\n",
      "        [    6, 50256, 50256, 50256, 50256],\n",
      "        [    8,     9, 50256, 50256, 50256]])\n"
     ]
    }
   ],
   "source": [
    "def custom_collate_draft_2(\n",
    "    batch,\n",
    "    pad_token_id=50256,\n",
    "    device=\"cpu\"\n",
    "):\n",
    "    # Find the longest sequence in the batch\n",
    "    batch_max_length = max(len(item)+1 for item in batch)\n",
    "\n",
    "    # Pad and prepare inputs\n",
    "    inputs_lst, targets_lst = [], []\n",
    "\n",
    "    for item in batch:\n",
    "        new_item = item.copy()\n",
    "        # Add an <|endoftext|> token\n",
    "        new_item += [pad_token_id]\n",
    "        # Pad sequences to max_length\n",
    "        padded = (\n",
    "            new_item + [pad_token_id] *\n",
    "            (batch_max_length - len(new_item))\n",
    "        )\n",
    "        inputs = torch.tensor(padded[:-1])  # Truncate the last token for inputs\n",
    "        targets = torch.tensor(padded[1:])  # Shift +1 to the right for targets\n",
    "        inputs_lst.append(inputs)\n",
    "        targets_lst.append(targets)\n",
    "\n",
    "    # Convert list of inputs to tensor and transfer to target device\n",
    "    inputs_tensor = torch.stack(inputs_lst).to(device)\n",
    "    targets_tensor = torch.stack(targets_lst).to(device)\n",
    "    return inputs_tensor, targets_tensor\n",
    "\n",
    "inputs, targets = custom_collate_draft_2(batch)\n",
    "print(inputs)\n",
    "print(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "154dd22e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    0,     1,     2,     3,     4],\n",
      "        [    5,     6, 50256, 50256, 50256],\n",
      "        [    7,     8,     9, 50256, 50256]])\n",
      "tensor([[    1,     2,     3,     4, 50256],\n",
      "        [    6, 50256,  -100,  -100,  -100],\n",
      "        [    8,     9, 50256,  -100,  -100]])\n"
     ]
    }
   ],
   "source": [
    "def custom_collate_fn(\n",
    "    batch,\n",
    "    pad_token_id=50256,\n",
    "    ignore_index=-100,\n",
    "    allowed_max_length=None,\n",
    "    device=\"cpu\"\n",
    "):\n",
    "    # Find the longest sequence in the batch\n",
    "    batch_max_length = max(len(item)+1 for item in batch)\n",
    "\n",
    "    # Pad and prepare inputs and targets\n",
    "    inputs_lst, targets_lst = [], []\n",
    "\n",
    "    for item in batch:\n",
    "        new_item = item.copy()\n",
    "        # Add an <|endoftext|> token\n",
    "        new_item += [pad_token_id]\n",
    "        # Pad sequences to max_length\n",
    "        padded = (\n",
    "            new_item + [pad_token_id] *\n",
    "            (batch_max_length - len(new_item))\n",
    "        )\n",
    "        inputs = torch.tensor(padded[:-1])  # Truncate the last token for inputs\n",
    "        targets = torch.tensor(padded[1:])  # Shift +1 to the right for targets\n",
    "\n",
    "        # New: Replace all but the first padding tokens in targets by ignore_index\n",
    "        mask = targets == pad_token_id\n",
    "        indices = torch.nonzero(mask).squeeze()\n",
    "        if indices.numel() > 1:\n",
    "            targets[indices[1:]] = ignore_index\n",
    "\n",
    "        # New: Optionally truncate to maximum sequence length\n",
    "        if allowed_max_length is not None:\n",
    "            inputs = inputs[:allowed_max_length]\n",
    "            targets = targets[:allowed_max_length]\n",
    "\n",
    "        inputs_lst.append(inputs)\n",
    "        targets_lst.append(targets)\n",
    "\n",
    "    # Convert list of inputs and targets to tensors and transfer to target device\n",
    "    inputs_tensor = torch.stack(inputs_lst).to(device)\n",
    "    targets_tensor = torch.stack(targets_lst).to(device)\n",
    "\n",
    "    return inputs_tensor, targets_tensor\n",
    "\n",
    "inputs, targets = custom_collate_fn(batch)\n",
    "print(inputs)\n",
    "print(targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0902d686",
   "metadata": {},
   "source": [
    "### Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5e1a6bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "from functools import partial\n",
    "\n",
    "customized_collate_fn = partial(\n",
    "    custom_collate_fn,\n",
    "    device=device,\n",
    "    allowed_max_length=1024\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c7993f52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loader:\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 76]) torch.Size([8, 76])\n",
      "torch.Size([8, 73]) torch.Size([8, 73])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 72]) torch.Size([8, 72])\n",
      "torch.Size([8, 80]) torch.Size([8, 80])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 62]) torch.Size([8, 62])\n",
      "torch.Size([8, 75]) torch.Size([8, 75])\n",
      "torch.Size([8, 62]) torch.Size([8, 62])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 77]) torch.Size([8, 77])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n",
      "torch.Size([8, 79]) torch.Size([8, 79])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 80]) torch.Size([8, 80])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 60]) torch.Size([8, 60])\n",
      "torch.Size([8, 59]) torch.Size([8, 59])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n",
      "torch.Size([8, 63]) torch.Size([8, 63])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 76]) torch.Size([8, 76])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 91]) torch.Size([8, 91])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 75]) torch.Size([8, 75])\n",
      "torch.Size([8, 89]) torch.Size([8, 89])\n",
      "torch.Size([8, 59]) torch.Size([8, 59])\n",
      "torch.Size([8, 88]) torch.Size([8, 88])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 70]) torch.Size([8, 70])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 74]) torch.Size([8, 74])\n",
      "torch.Size([8, 76]) torch.Size([8, 76])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 75]) torch.Size([8, 75])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 60]) torch.Size([8, 60])\n",
      "torch.Size([8, 60]) torch.Size([8, 60])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 80]) torch.Size([8, 80])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 58]) torch.Size([8, 58])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 63]) torch.Size([8, 63])\n",
      "torch.Size([8, 87]) torch.Size([8, 87])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 60]) torch.Size([8, 60])\n",
      "torch.Size([8, 72]) torch.Size([8, 72])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 70]) torch.Size([8, 70])\n",
      "torch.Size([8, 57]) torch.Size([8, 57])\n",
      "torch.Size([8, 72]) torch.Size([8, 72])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 62]) torch.Size([8, 62])\n",
      "torch.Size([8, 74]) torch.Size([8, 74])\n",
      "torch.Size([8, 80]) torch.Size([8, 80])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 70]) torch.Size([8, 70])\n",
      "torch.Size([8, 91]) torch.Size([8, 91])\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 80]) torch.Size([8, 80])\n",
      "torch.Size([8, 81]) torch.Size([8, 81])\n",
      "torch.Size([8, 74]) torch.Size([8, 74])\n",
      "torch.Size([8, 82]) torch.Size([8, 82])\n",
      "torch.Size([8, 63]) torch.Size([8, 63])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 77]) torch.Size([8, 77])\n",
      "torch.Size([8, 91]) torch.Size([8, 91])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 75]) torch.Size([8, 75])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 78]) torch.Size([8, 78])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 74]) torch.Size([8, 74])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "num_workers = 0\n",
    "batch_size = 8\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "train_dataset = InstructionDataset(train_data, tokenizer)\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=customized_collate_fn,\n",
    "    shuffle=True,\n",
    "    drop_last=True,\n",
    "    num_workers=num_workers\n",
    ")\n",
    "\n",
    "val_dataset = InstructionDataset(val_data, tokenizer)\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=customized_collate_fn,\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    "    num_workers=num_workers\n",
    ")\n",
    "\n",
    "test_dataset = InstructionDataset(test_data, tokenizer)\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=customized_collate_fn,\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    "    num_workers=num_workers\n",
    ")\n",
    "\n",
    "print(\"Train loader:\")\n",
    "for inputs, targets in train_loader:\n",
    "    print(inputs.shape, targets.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "95014f2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "          257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "        21017, 46486,    25,   198, 30003,  6525,   262,  6827,  1262,   257,\n",
      "          985,   576,    13,   198,   198, 21017, 23412,    25,   198,   464,\n",
      "         5156,   318,   845, 13779,    13,   198,   198, 21017, 18261,    25,\n",
      "          198,   464,  5156,   318,   355, 13779,   355,   257,  4936,    13,\n",
      "        50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256])\n",
      "tensor([  318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,   257,\n",
      "         2882,   326, 20431, 32543,   262,  2581,    13,   198,   198, 21017,\n",
      "        46486,    25,   198, 30003,  6525,   262,  6827,  1262,   257,   985,\n",
      "          576,    13,   198,   198, 21017, 23412,    25,   198,   464,  5156,\n",
      "          318,   845, 13779,    13,   198,   198, 21017, 18261,    25,   198,\n",
      "          464,  5156,   318,   355, 13779,   355,   257,  4936,    13, 50256,\n",
      "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100])\n"
     ]
    }
   ],
   "source": [
    "print(inputs[0])\n",
    "\n",
    "print(targets[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4124fd7",
   "metadata": {},
   "source": [
    "## Load Pre-trained LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8a2c3015",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists and is up-to-date: gpt2/355M/checkpoint\n",
      "File already exists and is up-to-date: gpt2/355M/encoder.json\n",
      "File already exists and is up-to-date: gpt2/355M/hparams.json\n",
      "File already exists and is up-to-date: gpt2/355M/model.ckpt.data-00000-of-00001\n",
      "File already exists and is up-to-date: gpt2/355M/model.ckpt.index\n",
      "File already exists and is up-to-date: gpt2/355M/model.ckpt.meta\n",
      "File already exists and is up-to-date: gpt2/355M/vocab.bpe\n"
     ]
    }
   ],
   "source": [
    "from gpt_download import download_and_load_gpt2\n",
    "from utils2 import GPTModel, load_weights_into_gpt\n",
    "\n",
    "\n",
    "BASE_CONFIG = {\n",
    "    \"vocab_size\": 50257,     # Vocabulary size\n",
    "    \"context_length\": 1024,  # Context length\n",
    "    \"drop_rate\": 0.0,        # Dropout rate\n",
    "    \"qkv_bias\": True         # Query-key-value bias\n",
    "}\n",
    "\n",
    "model_configs = {\n",
    "    \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
    "    \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
    "    \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
    "    \"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
    "}\n",
    "\n",
    "CHOOSE_MODEL = \"gpt2-medium (355M)\"\n",
    "\n",
    "BASE_CONFIG.update(model_configs[CHOOSE_MODEL])\n",
    "\n",
    "model_size = CHOOSE_MODEL.split(\" \")[-1].lstrip(\"(\").rstrip(\")\")\n",
    "settings, params = download_and_load_gpt2(\n",
    "    model_size=model_size,\n",
    "    models_dir=\"gpt2\"\n",
    ")\n",
    "\n",
    "model = GPTModel(BASE_CONFIG)\n",
    "load_weights_into_gpt(model, params)\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bdd2d912",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Convert the active sentence to passive: 'The chef cooks the meal every day.'\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "input_text = format_input(val_data[0])\n",
    "\n",
    "print(input_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e3baa41e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The chef cooks the meal every day.\n",
      "\n",
      "### Instruction:\n",
      "\n",
      "Convert the active sentence to passive: 'The chef cooks the\n"
     ]
    }
   ],
   "source": [
    "from utils3 import generate, text_to_token_ids, token_ids_to_text\n",
    "\n",
    "token_ids = generate(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(input_text, tokenizer),\n",
    "    max_new_tokens=35,\n",
    "    context_size=BASE_CONFIG[\"context_length\"],\n",
    "    eos_id=50256,\n",
    ")\n",
    "generated_text = token_ids_to_text(token_ids, tokenizer)\n",
    "response_text = (\n",
    "    generated_text[len(input_text):]\n",
    "    .replace(\"### Response:\", \"\")\n",
    "    .strip()\n",
    ")\n",
    "\n",
    "print(response_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fef396ba",
   "metadata": {},
   "source": [
    "## SFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4f21476f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 3.825879430770874\n",
      "Validation loss: 3.761904001235962\n"
     ]
    }
   ],
   "source": [
    "from utils3 import calc_loss_loader, train_model_simple\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "with torch.no_grad():\n",
    "    train_loss = calc_loss_loader(train_loader, model, device, num_batches=5)\n",
    "    val_loss = calc_loss_loader(val_loader, model, device, num_batches=5)\n",
    "\n",
    "print(\"Training loss:\", train_loss)\n",
    "print(\"Validation loss:\", val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "41ec91f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1 (Step 000000): Train loss 2.637, Val loss 2.626\n",
      "Ep 1 (Step 000005): Train loss 1.174, Val loss 1.102\n",
      "Ep 1 (Step 000010): Train loss 0.872, Val loss 0.945\n",
      "Ep 1 (Step 000015): Train loss 0.856, Val loss 0.906\n",
      "Ep 1 (Step 000020): Train loss 0.776, Val loss 0.881\n",
      "Ep 1 (Step 000025): Train loss 0.753, Val loss 0.859\n",
      "Ep 1 (Step 000030): Train loss 0.798, Val loss 0.836\n",
      "Ep 1 (Step 000035): Train loss 0.715, Val loss 0.809\n",
      "Ep 1 (Step 000040): Train loss 0.672, Val loss 0.806\n",
      "Ep 1 (Step 000045): Train loss 0.633, Val loss 0.790\n",
      "Ep 1 (Step 000050): Train loss 0.662, Val loss 0.783\n",
      "Ep 1 (Step 000055): Train loss 0.760, Val loss 0.764\n",
      "Ep 1 (Step 000060): Train loss 0.719, Val loss 0.743\n",
      "Ep 1 (Step 000065): Train loss 0.652, Val loss 0.735\n",
      "Ep 1 (Step 000070): Train loss 0.532, Val loss 0.729\n",
      "Ep 1 (Step 000075): Train loss 0.569, Val loss 0.729\n",
      "Ep 1 (Step 000080): Train loss 0.605, Val loss 0.725\n",
      "Ep 1 (Step 000085): Train loss 0.509, Val loss 0.710\n",
      "Ep 1 (Step 000090): Train loss 0.562, Val loss 0.691\n",
      "Ep 1 (Step 000095): Train loss 0.500, Val loss 0.682\n",
      "Ep 1 (Step 000100): Train loss 0.502, Val loss 0.677\n",
      "Ep 1 (Step 000105): Train loss 0.564, Val loss 0.670\n",
      "Ep 1 (Step 000110): Train loss 0.555, Val loss 0.667\n",
      "Ep 1 (Step 000115): Train loss 0.508, Val loss 0.664\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: Convert the active sentence to passive: 'The chef cooks the meal every day.'  ### Response: The meal is prepared every day by the chef.<|endoftext|>The following is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: Convert the active sentence to passive:\n",
      "Ep 2 (Step 000120): Train loss 0.435, Val loss 0.672\n",
      "Ep 2 (Step 000125): Train loss 0.450, Val loss 0.687\n",
      "Ep 2 (Step 000130): Train loss 0.447, Val loss 0.682\n",
      "Ep 2 (Step 000135): Train loss 0.404, Val loss 0.681\n",
      "Ep 2 (Step 000140): Train loss 0.409, Val loss 0.680\n",
      "Ep 2 (Step 000145): Train loss 0.368, Val loss 0.680\n",
      "Ep 2 (Step 000150): Train loss 0.381, Val loss 0.675\n",
      "Ep 2 (Step 000155): Train loss 0.412, Val loss 0.676\n",
      "Ep 2 (Step 000160): Train loss 0.415, Val loss 0.683\n",
      "Ep 2 (Step 000165): Train loss 0.379, Val loss 0.686\n",
      "Ep 2 (Step 000170): Train loss 0.324, Val loss 0.684\n",
      "Ep 2 (Step 000175): Train loss 0.338, Val loss 0.672\n",
      "Ep 2 (Step 000180): Train loss 0.391, Val loss 0.658\n",
      "Ep 2 (Step 000185): Train loss 0.415, Val loss 0.659\n",
      "Ep 2 (Step 000190): Train loss 0.340, Val loss 0.650\n",
      "Ep 2 (Step 000195): Train loss 0.329, Val loss 0.637\n",
      "Ep 2 (Step 000200): Train loss 0.310, Val loss 0.636\n",
      "Ep 2 (Step 000205): Train loss 0.351, Val loss 0.632\n",
      "Ep 2 (Step 000210): Train loss 0.366, Val loss 0.632\n",
      "Ep 2 (Step 000215): Train loss 0.396, Val loss 0.637\n",
      "Ep 2 (Step 000220): Train loss 0.298, Val loss 0.649\n",
      "Ep 2 (Step 000225): Train loss 0.346, Val loss 0.661\n",
      "Ep 2 (Step 000230): Train loss 0.293, Val loss 0.658\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: Convert the active sentence to passive: 'The chef cooks the meal every day.'  ### Response: The meal is cooked every day by the chef.<|endoftext|>The following is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: What is the capital of the United Kingdom\n",
      "Training completed in 10.71 minutes.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.00005, weight_decay=0.1)\n",
    "\n",
    "num_epochs = 2\n",
    "\n",
    "train_losses, val_losses, tokens_seen = train_model_simple(\n",
    "    model, train_loader, val_loader, optimizer, device,\n",
    "    num_epochs=num_epochs, eval_freq=5, eval_iter=5,\n",
    "    start_context=format_input(val_data[0]), tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "end_time = time.time()\n",
    "execution_time_minutes = (end_time - start_time) / 60\n",
    "print(f\"Training completed in {execution_time_minutes:.2f} minutes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "98840c6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from utils3 import plot_losses\n",
    "\n",
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
    "plot_losses(epochs_tensor, tokens_seen, train_losses, val_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c00984dd",
   "metadata": {},
   "source": [
    "## Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ebdd0c55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Rewrite the sentence using a simile.\n",
      "\n",
      "### Input:\n",
      "The car is very fast.\n",
      "\n",
      "Correct response:\n",
      ">> The car is as fast as lightning.\n",
      "\n",
      "Model response:\n",
      ">> The car is as fast as a bullet.\n",
      "-------------------------------------\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "What type of cloud is typically associated with thunderstorms?\n",
      "\n",
      "Correct response:\n",
      ">> The type of cloud typically associated with thunderstorms is cumulonimbus.\n",
      "\n",
      "Model response:\n",
      ">> The type of cloud associated with thunderstorms is a cumulus cloud.\n",
      "-------------------------------------\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Name the author of 'Pride and Prejudice'.\n",
      "\n",
      "Correct response:\n",
      ">> Jane Austen.\n",
      "\n",
      "Model response:\n",
      ">> The author of 'Pride and Prejudice' is Jane Austen.\n",
      "-------------------------------------\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "for entry in test_data[:3]:\n",
    "    input_text = format_input(entry)\n",
    "    token_ids = generate(\n",
    "        model=model,\n",
    "        idx=text_to_token_ids(input_text, tokenizer).to(device),\n",
    "        max_new_tokens=256,\n",
    "        context_size=BASE_CONFIG[\"context_length\"],\n",
    "        eos_id=50256\n",
    "    )\n",
    "    generated_text = token_ids_to_text(token_ids, tokenizer)\n",
    "    response_text = (\n",
    "        generated_text[len(input_text):]\n",
    "        .replace(\"### Response:\", \"\")\n",
    "        .strip()\n",
    "    )\n",
    "    print(input_text)\n",
    "    print(f\"\\nCorrect response:\\n>> {entry['output']}\")\n",
    "    print(f\"\\nModel response:\\n>> {response_text.strip()}\")\n",
    "    print(\"-------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f1bb1dde",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 110/110 [03:40<00:00,  2.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'instruction': 'Rewrite the sentence using a simile.', 'input': 'The car is very fast.', 'output': 'The car is as fast as lightning.', 'model_response': 'The car is as fast as a bullet.'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "for i, entry in tqdm(enumerate(test_data), total=len(test_data)):\n",
    "    input_text = format_input(entry)\n",
    "\n",
    "    token_ids = generate(\n",
    "        model=model,\n",
    "        idx=text_to_token_ids(input_text, tokenizer).to(device),\n",
    "        max_new_tokens=256,\n",
    "        context_size=BASE_CONFIG[\"context_length\"],\n",
    "        eos_id=50256\n",
    "    )\n",
    "    generated_text = token_ids_to_text(token_ids, tokenizer)\n",
    "    response_text = generated_text[len(input_text):].replace(\"### Response:\", \"\").strip()\n",
    "    test_data[i][\"model_response\"] = response_text\n",
    "\n",
    "with open(\"instruction-data-with-response.json\", \"w\") as file:\n",
    "    json.dump(test_data, file, indent=4)  # \"indent\" for pretty-printing\n",
    "\n",
    "print(test_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "938b534f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved as gpt2-medium355M-sft.pth\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "file_name = f\"{re.sub(r'[ ()]', '', CHOOSE_MODEL) }-sft.pth\"\n",
    "torch.save(model.state_dict(), file_name)\n",
    "print(f\"Model saved as {file_name}\")\n",
    "\n",
    "# Load model via\n",
    "# model.load_state_dict(torch.load(\"gpt2-medium355M-sft.pth\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "019649f2",
   "metadata": {},
   "source": [
    "## Use the SFT-ed Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa519974",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a65eadde",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2aac236",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
